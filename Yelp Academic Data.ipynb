{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"proj4.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Mongo \n",
    "\n",
    "## Due Date: Friday 11/18, 11:59 PM\n",
    "### Checkpoint: Thursday 11/10, 11:59 PM\n",
    "\n",
    "In this project, we will be investigating how different database systems handle semi-structured JSON data. In particular, we will be placing emphasis on the use of MongoDB: a database system that stores data in a construct known as documents. These documents are very similar to the JSON objects we've explored in lecture with a few differences in representation and indexing that we will explore in the following questions. In this project, we will be working with the Yelp Academic Dataset which contains a dataset of `businesses`, `reviews`, and `users`. Due to the limitations of JupyterHub and the Mongo instances we are working with, `reviews` and `users` are truncated to 7500 reviews and 1000 users. We will be using the full `businesses` dataset, however.\n",
    "\n",
    "Throughout the course of this project, you should understand what Mongo can (and cannot) do with regards to its documents as a NoSQL datastore and compare and contrast this to other data representation formats such as the relational model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics & Scoring Breakdown\n",
    "\n",
    "For Data 101 students, this project is worth 15% of your grade. For Info 258 students, this project is worth 12% of your grade.\n",
    "\n",
    "If you make a non-trivial submission to the **Project 4 \\[CHECKPOINT\\]** assignment on Gradescope before **Thursday 11/10 11:59PM**, you will earn an extra credit point on this project. We will define \"non-trivial\" as scoring at least 5 points on the coding portion of the assignment. If you pass all the public tests in Question 1, you are guaranteed to receive the extra credit point. No late submissions will be allowed for the checkpoint.\n",
    "\n",
    "For the final submission that will be graded, please submit to **Project 4 \\[FINAL\\]** assignment on Gradescope. Please read the submission instructions carefully and double check that your submission is not throwing any errors.\n",
    "\n",
    "Each coding question has **both public tests and hidden tests**. Roughly 50% of your coding grade will be made up of your score on the public tests released to you, while the remaining 50% will be made up of unreleased hidden tests. Free-response questions will be manually graded.\n",
    "\n",
    "This is an **individual project**. However, you’re welcome to collaborate with any other student in the class as long as it’s within the academic honesty guidelines.\n",
    "\n",
    "Question | Points\n",
    "--- | ---\n",
    "1a\t| 1\n",
    "1b  | 1\n",
    "1c\t| 2\n",
    "1d\t| 1\n",
    "1e\t| 2\n",
    "1f  | 1\n",
    "2a\t| 2\n",
    "2b\t| 1\n",
    "2c  | 1\n",
    "2d  | 2\n",
    "3a\t| 1\n",
    "3b\t| 1\n",
    "3c\t| 1\n",
    "3d  | 1\n",
    "3e  | 1\n",
    "3f  | 3\n",
    "4a\t| 1\n",
    "4b\t| 2\n",
    "4c\t| 2\n",
    "4d  | 1\n",
    "**Total** | 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Up Mongo\n",
    "We will be using Pymongo, a Python wrapper for MongoDB, for this project. Every student should have access to their own MongoDB instance, running on the localhost of your Datahub server. After running the following cell, for the rest of the project, you can use the Python variables business, review, and user to access the corresponding collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from pymongo import TEXT\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost\")\n",
    "mydb = myclient[\"yelp\"]\n",
    "business = mydb[\"business\"]\n",
    "review = mydb[\"review\"]\n",
    "user = mydb[\"user\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "**PLEASE READ:** Please avoid printing too much debugging query output - it may crash your Jupyter Hub if your file size becomes too large! It's recommended to delete any debugging query cells if no longer needed as you go through the project.\n",
    "\n",
    "You might run into issues on the project where you are certain your code works but the output is incorrect. This may be because your collections have been corrupted. Run the following cell and uncomment the specific collections you would like to drop if you would like to remake your collections from scratch. **Be sure to re-run the Load Datasets cells below if you drop your collections so you aren't working with empty collections!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT AND RUN THIS CELL IF YOU WOULD LIKE TO REMAKE YOUR COLLECTIONS FROM SCRATCH. \n",
    "# IF YOU DROP ANY COLLECTIONS, RE-RUN THE NEXT TWO CELLS TO LOAD IN THE DATA.\n",
    "\n",
    "# review.drop()\n",
    "# business.drop()\n",
    "# user.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n",
    "The following 2 cells will load the JSON datasets into the appropriate Mongo collections. You will only need to run them once unless you drop the collections above. The second cell **may take a couple of minutes to run** if you are running it for the first time or are running it after you dropped the collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os.path\n",
    "\n",
    "if not os.path.isfile('data/yelp_academic_dataset_review.json'):\n",
    "    with zipfile.ZipFile('data/yelp_academic_dataset_review.json.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "\n",
    "if not os.path.isfile('data/yelp_academic_dataset_user.json'):\n",
    "    with zipfile.ZipFile('data/yelp_academic_dataset_user.json.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "\n",
    "if not os.path.isfile('data/yelp_academic_dataset_business.json'):\n",
    "    with zipfile.ZipFile('data/yelp_academic_dataset_business.json.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS CELL MAY TAKE AT MOST 5 MINUTES. BUT HOPEFULLY YOU WILL ONLY NEED TO RUN IT ONCE.\n",
    "import json\n",
    "\n",
    "if business.count_documents({}) == 0:\n",
    "    print(\"Loading business collection...\")\n",
    "    with open('data/yelp_academic_dataset_business.json', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            business.insert_one(json.loads(line))\n",
    "\n",
    "if review.count_documents({}) == 0:\n",
    "    print(\"Loading review collection...\")\n",
    "    with open('data/yelp_academic_dataset_review.json', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            review.insert_one(json.loads(line))\n",
    "            \n",
    "if user.count_documents({}) == 0:\n",
    "    print(\"Loading user collection...\")\n",
    "    with open('data/yelp_academic_dataset_user.json', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            user.insert_one(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at our collections. For the command below, replace `user` with `review` or `business` to count the number of documents in each collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160585"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's inspect our collections. Replace `business` with `review` and `user` to see the first document in each collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('636dacbe71336d3423ea2668'),\n",
       " 'business_id': '6iYb2HFDywm3zjuRg0shjw',\n",
       " 'name': 'Oskar Blues Taproom',\n",
       " 'address': '921 Pearl St',\n",
       " 'city': 'Boulder',\n",
       " 'state': 'CO',\n",
       " 'postal_code': '80302',\n",
       " 'latitude': 40.0175444,\n",
       " 'longitude': -105.2833481,\n",
       " 'stars': 4.0,\n",
       " 'review_count': 86,\n",
       " 'is_open': 1,\n",
       " 'attributes': {'RestaurantsTableService': 'True',\n",
       "  'WiFi': \"u'free'\",\n",
       "  'BikeParking': 'True',\n",
       "  'BusinessParking': \"{'garage': False, 'street': True, 'validated': False, 'lot': False, 'valet': False}\",\n",
       "  'BusinessAcceptsCreditCards': 'True',\n",
       "  'RestaurantsReservations': 'False',\n",
       "  'WheelchairAccessible': 'True',\n",
       "  'Caters': 'True',\n",
       "  'OutdoorSeating': 'True',\n",
       "  'RestaurantsGoodForGroups': 'True',\n",
       "  'HappyHour': 'True',\n",
       "  'BusinessAcceptsBitcoin': 'False',\n",
       "  'RestaurantsPriceRange2': '2',\n",
       "  'Ambience': \"{'touristy': False, 'hipster': False, 'romantic': False, 'divey': False, 'intimate': False, 'trendy': False, 'upscale': False, 'classy': False, 'casual': True}\",\n",
       "  'HasTV': 'True',\n",
       "  'Alcohol': \"'beer_and_wine'\",\n",
       "  'GoodForMeal': \"{'dessert': False, 'latenight': False, 'lunch': False, 'dinner': False, 'brunch': False, 'breakfast': False}\",\n",
       "  'DogsAllowed': 'False',\n",
       "  'RestaurantsTakeOut': 'True',\n",
       "  'NoiseLevel': \"u'average'\",\n",
       "  'RestaurantsAttire': \"'casual'\",\n",
       "  'RestaurantsDelivery': 'None'},\n",
       " 'categories': 'Gastropubs, Food, Beer Gardens, Restaurants, Bars, American (Traditional), Beer Bar, Nightlife, Breweries',\n",
       " 'hours': {'Monday': '11:0-23:0',\n",
       "  'Tuesday': '11:0-23:0',\n",
       "  'Wednesday': '11:0-23:0',\n",
       "  'Thursday': '11:0-23:0',\n",
       "  'Friday': '11:0-23:0',\n",
       "  'Saturday': '11:0-23:0',\n",
       "  'Sunday': '11:0-23:0'}}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see a document containing a business named `Oskar Blues Taproom` when you run the command above, it means that our JSON data has successfully been imported into the collection! Now we can get started with exploring Mongo in a bit more detail.\n",
    "\n",
    "**Todo:** Run the two cells below for grading purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "!mkdir -p results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Basic MQL\n",
    "\n",
    "### Question 1a\n",
    "\n",
    "In lecture, we discussed how one could find specific attributes from a JSON object using dot notation. \n",
    "\n",
    "While you can still use the dot notation in queries, PyMongo represents documents returned from Mongo queries using Python dictionaries, making it convenient to manipulate JSON using a mix of Mongo queries and array indexing. Specifically, given the result of a retrieval `find` query, you can look up the third document by appending `[2]`. Then, given this document, you can look up the field `'amount'` by appending `['amount']` etc., adding multiple square brackets as needed to \"walk down\" the JSON tree representation via `collection.find(...)[2]['amount']`.\n",
    "\n",
    "In order to get a visual output of the query results, you will need to wrap `collection.find(...)` inside `list()`, e.g. `list(collection.find(...))`. This is because `collection.find(...)` returns a **Cursor** object, which is an iterator. **An important consequence** is that if we set `result = collection.find(...)`, then calling `list(result)` for the first time will get you the expected list of documents in the query result, but calling `list(result)` for a second time will give you an empty list! So wrapping `collection.find(...)` directly inside `list()` would avoid this issue.\n",
    "\n",
    "Another note - since we are using Python dictionaries as our query filter, make sure to wrap all keys and values inside quotes.\n",
    "\n",
    "As a warmup to get you familiarized with PyMongo syntax, find the Tuesday hours for the restaurant named **Legal Sea Foods** at **100 Huntington Ave** in **Boston**. Be careful - there are many Legal Sea Foods in Boston!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_1a = list(business.find({\"name\": \"Legal Sea Foods\", \"address\": \"100 Huntington Ave\", \"city\": \"Boston\"}, {\"hours\": 1}))[0][\"hours\"][\"Tuesday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "pickle.dump(result_1a, open(\"results/result_1a.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1a</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1a results: All test cases passed!"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1b\n",
    "Now let's get some practice with aggregation and filtering. Our goal is to write a query that computes the average star rating for all businesses in Colorado with 30 reviews or greater. However, this won't be as easy as setting the state to CO! If we inspect this dataset more closely, we will notice that some cities are not matched up with the right states. As an example, run the query below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('636dacbf71336d3423ea2d83'),\n",
       "  'business_id': 'SNCRnaSy6E5fHgQuoCmmbQ',\n",
       "  'name': 'Katia Photography',\n",
       "  'address': '',\n",
       "  'city': 'Portland',\n",
       "  'state': 'CA',\n",
       "  'postal_code': '97007',\n",
       "  'latitude': 45.4501529,\n",
       "  'longitude': -122.8849111,\n",
       "  'stars': 5.0,\n",
       "  'review_count': 11,\n",
       "  'is_open': 1,\n",
       "  'attributes': {'BusinessAcceptsBitcoin': 'False',\n",
       "   'BusinessAcceptsCreditCards': 'True',\n",
       "   'WiFi': \"u'no'\"},\n",
       "  'categories': 'Shopping, Clothing Rental, Event Planning & Services, Fashion, Event Photography, Photographers, Session Photography',\n",
       "  'hours': {'Monday': '8:0-22:0',\n",
       "   'Tuesday': '8:0-22:0',\n",
       "   'Wednesday': '8:0-22:0',\n",
       "   'Thursday': '8:0-22:0',\n",
       "   'Friday': '8:0-22:0',\n",
       "   'Saturday': '8:0-22:0',\n",
       "   'Sunday': '8:0-22:0'}},\n",
       " {'_id': ObjectId('636dacd171336d3423ea9def'),\n",
       "  'business_id': 'cjwnQMQOGOYgB5uNmiYWLA',\n",
       "  'name': 'Verizon Authorized Retailer - GoWireless',\n",
       "  'address': '4655 SW Griffith Dr, Ste 125',\n",
       "  'city': 'Beaverton',\n",
       "  'state': 'CA',\n",
       "  'postal_code': '97005',\n",
       "  'latitude': 45.486312,\n",
       "  'longitude': -122.796487,\n",
       "  'stars': 2.5,\n",
       "  'review_count': 9,\n",
       "  'is_open': 0,\n",
       "  'attributes': {'BusinessAcceptsCreditCards': 'True',\n",
       "   'BusinessParking': 'None',\n",
       "   'ByAppointmentOnly': 'False',\n",
       "   'BikeParking': 'True'},\n",
       "  'categories': 'Mobile Phones, Telecommunications, Shopping, Home Services, IT Services & Computer Repair, Internet Service Providers, Local Services, Professional Services, Mobile Phone Accessories, Electronics',\n",
       "  'hours': {'Monday': '0:0-0:0',\n",
       "   'Tuesday': '10:0-18:0',\n",
       "   'Wednesday': '10:0-18:0',\n",
       "   'Thursday': '10:0-18:0',\n",
       "   'Friday': '10:0-18:0',\n",
       "   'Saturday': '10:0-18:0',\n",
       "   'Sunday': '11:0-18:0'}},\n",
       " {'_id': ObjectId('636dacda71336d3423eae0d6'),\n",
       "  'business_id': 'l92RJMHpxZgJl7FQuqpW6w',\n",
       "  'name': 'Here We Grow',\n",
       "  'address': '',\n",
       "  'city': 'Atlanta',\n",
       "  'state': 'CA',\n",
       "  'postal_code': '30345',\n",
       "  'latitude': 33.8484195,\n",
       "  'longitude': -84.2858121,\n",
       "  'stars': 5.0,\n",
       "  'review_count': 6,\n",
       "  'is_open': 1,\n",
       "  'attributes': {'GoodForKids': 'True'},\n",
       "  'categories': 'Childbirth Education, Specialty Schools, Preschools, Adult Education, Parenting Classes, Education, Active Life, Kids Activities',\n",
       "  'hours': {'Tuesday': '9:0-17:0',\n",
       "   'Thursday': '9:0-17:0',\n",
       "   'Saturday': '9:0-13:0',\n",
       "   'Sunday': '11:0-15:0'}}]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(business.find({\"state\": \"CA\"}).limit(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how cities like Portland and Atlanta, and Orlando are classified as California cities! However, the latitude and longitude is generally correct. The latitude of Colorado is between 37 and 41 **inclusive** and the longitude is between -109 and -102 **inclusive**. Now, use this to **find the average star rating** of all businesses in this range with **30 or more reviews**.\n",
    "\n",
    "Recall that in SQL, we would use a GROUP BY with the AVG aggregation function. In Mongo, we use an aggregation pipeline, comprised of multiple stages. Each stage transforms the documents in some way. Pipeline stages do not need to produce one output document for every input document. For example, some stages may generate new documents or filter out documents.\n",
    "\n",
    "**Hint 1**: as in the previous question, you may find it helpful to use the PyMongo array notation to extract the pertinent information once you have composed the right Mongo aggregation query. You are required to wrap `collection.aggregate(...)` inside `list()`, e.g. `list(collection.aggregate(...))` before indexing / visualizing the output. Similar to `collection.find(...)`, `collection.aggregate(...)` also returns a **Cursor** object (which is an iterator).\n",
    "\n",
    "**Hint 2**: you can set multiple conditions for a given field within the same object, e.g. `{\"$gte\": 0, \"$lte\": 10}`. This is the recommended approach, or else you may need to worry about the ordering between the conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6735412474849096"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result_1b = list(business.aggregate([\n",
    "    {'$match': {'latitude': {'$gte': 37, '$lte': 41},\n",
    "            'longitude': {'$gte': -109, '$lte': -102},\n",
    "            'review_count': {'$gte': 30}}},\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': '$state',\n",
    "            'avg_stars': {\"$avg\": \"$stars\"}}}]))[0]['avg_stars']\n",
    "result_1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "pickle.dump(result_1b, open(\"results/result_1b.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1b</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1b results: All test cases passed!"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1c\n",
    "\n",
    "In this question, we will explore aggregation and grouping further. We will also make use of the `$project` operator which allows us to output documents with certain fields of our choosing. \n",
    "\n",
    "For this question, we would like to create an aggregation pipeline to find the town in each state with the highest average number of stars. **We will only consider towns with greater than or equal to 5 reviews in total across all the restaurants in that town so that the average is meaningful.** Your final output should contain exactly two fields: `city_state` which is the name of the town with the highest value of average stars in the state concatenated with a comma followed by the state initials and `averageStars` which contains the average number of stars for the corresponding town. To ensure your output is consistent with the autograder, sort in descending order by `averageStars` and break ties by sorting second on `city_state` in alphabetical (ascending) order.\n",
    "\n",
    "As a concrete example, imagine that Berkeley and Austin have the highest average stars in California and Texas respectively (and both have more than or equal to 5 total reviews). If Berkeley and Austin both have an average star rating of 5.0, your final output should be:\n",
    "\n",
    "```\n",
    "{'averageStars': 5.0, 'city_state': 'Austin, TX'}\n",
    "{'averageStars': 5.0, 'city_state': 'Berkeley, CA'}\n",
    "```\n",
    "\n",
    "**Note:** You will provide a pipeline to `business.aggregate(...)` as your solution. Save your pipeline to `q1c_pipeline`.\n",
    "\n",
    "**Hint:** You may find the `concat` operator helpful. See: https://docs.mongodb.com/manual/reference/operator/aggregation/concat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'averageStars': 5.0, 'city_state': 'Atlanda,GA'},\n",
       " {'averageStars': 5.0, 'city_state': 'Atlanta,CA'},\n",
       " {'averageStars': 5.0, 'city_state': 'Auatin,TX'},\n",
       " {'averageStars': 5.0, 'city_state': 'Beuna Vista,FL'},\n",
       " {'averageStars': 5.0, 'city_state': 'Boston-Winthrop,MA'},\n",
       " {'averageStars': 5.0, 'city_state': 'Everett,WA'},\n",
       " {'averageStars': 5.0, 'city_state': 'Grove city,OH'},\n",
       " {'averageStars': 5.0, 'city_state': 'Historic Milwaukie,OR'},\n",
       " {'averageStars': 5.0, 'city_state': 'Kings County,NY'},\n",
       " {'averageStars': 5.0, 'city_state': 'Toronto,ON'},\n",
       " {'averageStars': 5.0, 'city_state': 'Vancouver,DC'},\n",
       " {'averageStars': 5.0, 'city_state': 'Vancovuer,BC'},\n",
       " {'averageStars': 4.5, 'city_state': 'Jamestown,CO'},\n",
       " {'averageStars': 4.5, 'city_state': 'Portland,HI'},\n",
       " {'averageStars': 4.5, 'city_state': 'Powell,DE'},\n",
       " {'averageStars': 4.5, 'city_state': 'Salem,AZ'},\n",
       " {'averageStars': 4.5, 'city_state': 'Vancouver,ABE'},\n",
       " {'averageStars': 4.0, 'city_state': 'Franklin Park,IL'},\n",
       " {'averageStars': 4.0, 'city_state': 'Hampton,NH'},\n",
       " {'averageStars': 3.5, 'city_state': 'Austin,MN'},\n",
       " {'averageStars': 3.5, 'city_state': 'Glendale,WI'},\n",
       " {'averageStars': 3.5, 'city_state': 'Jackson,MI'},\n",
       " {'averageStars': 3.5, 'city_state': 'Norfolk,VA'},\n",
       " {'averageStars': 3.5, 'city_state': 'North Reading,ME'},\n",
       " {'averageStars': 3.5, 'city_state': 'Rio Rancho,NM'},\n",
       " {'averageStars': 2.5, 'city_state': 'Austin,AL'},\n",
       " {'averageStars': 2.5, 'city_state': 'Oklahoma City,OK'},\n",
       " {'averageStars': 2.5, 'city_state': 'Sanford,NC'},\n",
       " {'averageStars': 2.0, 'city_state': 'Ellsworth,KS'},\n",
       " {'averageStars': 2.0, 'city_state': 'Liberty,KY'},\n",
       " {'averageStars': 1.5, 'city_state': 'Sheridan,WY'}]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1c_pipeline = list([\n",
    "    {'$group' : {'_id': {'state' : '$state', 'city': '$city'}, 'total_review': {'$sum': '$review_count'}, 'averageStars': {'$avg' : '$stars'}}},\n",
    "    {'$match' : {'total_review': {'$gte' : 5}}},\n",
    "    {'$project': {'averageStars' : '$averageStars', 'city_state' : {'$concat' : ['$_id.city',',','$_id.state']}}}, \n",
    "    {'$sort' : {'averageStars' : -1, 'city_state' : 1}}, \n",
    "    {'$group' : {'_id' : '$_id.state', 'averageStars': {'$first' : '$averageStars'}, 'city_state' : {'$first': '$city_state'}}},\n",
    "    {'$sort': {'averageStars': -1, 'city_state' : 1}}, \n",
    "    {'$project' : {'_id' :0, 'averageStars': '$averageStars', 'city_state' : '$city_state'}}\n",
    "])\n",
    "\n",
    "result_1c = list(business.aggregate(q1c_pipeline))\n",
    "result_1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_1c = list(business.aggregate(q1c_pipeline))\n",
    "pickle.dump(result_1c, open(\"results/result_1c.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1c</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1c results: All test cases passed!"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1d\n",
    "\n",
    "In class, we've described structured (rectangular) data as well as semi-structured data. We haven't quite covered unstructured data -- this is basically free-form text. Often, in semi-structured JSON you may have unstructured text data embedded within, such as the text field in the review collection.\n",
    "\n",
    "MongoDB allows us to build a so-called **text index** to retrieve the relevant document based on keywords found in text in a predefined field. This index converts our free-form text into a structure that allows us to easily look up documents by its contents. To leverage this text search capability, we build a text index on the `text` field in the `review` collection. This has been done for you.\n",
    "\n",
    "We will then use this text index to do basic sentiment analysis and find all the restaurants we should avoid! Using the text index given, write a query to find all the reviews with \"disgusting\", \"horrible\", \"horrid\", \"gross\", \"bad\", or \"hate\". To use the text index, use the keywords `$text` and `$search` as detailed here: https://www.mongodb.com/docs/manual/core/text-search-operators/.\n",
    "\n",
    "Fill in your query into `result_1d` to count how many reviews contain any of these 6 words.\n",
    "\n",
    "**Hint:** In general, you can count the number of documents returned by a `find` query result via `len(list(collection.find(...)))` or more simply `collection.count_documents(...)`. To count the number of documents returned by an `aggregate` query result, the best way is to directly use `len(list(collection.aggregate(...)))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We create a text index here\n",
    "if 'text_text' not in review.index_information():\n",
    "    review.create_index([('text', TEXT)])\n",
    "query = {\n",
    "    \"$text\": {\"$search\": \"disgusting horrible horrid gross bad hate\"}\n",
    "}\n",
    "result_1d = review.count_documents(query) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "pickle.dump(result_1d, open(\"results/result_1d.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1d</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1d results: All test cases passed!"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1e\n",
    "\n",
    "Now let's learn Mongo updates, deletions, and creation. Create a new collection called `review_boolean` which is the exact same as `reviews` EXCEPT there is a new field called `to_avoid` which is the string \"true\"  if the review `text` contains the words \"disgusting\", \"horrid\", \"horrible\", \"gross\", \"bad\", or \"hate\" and the string \"false\" if not.  \n",
    "\n",
    "This is a tricky task! We have not discussed creation, updates, or insertions in great detail during lecture but luckily, Mongo uses a similar approach to SQL.\n",
    "\n",
    "*Insertions*: In order to insert into a document, you may use the functions [review_boolean.insert_one(...)](https://docs.mongodb.com/manual/reference/method/db.collection.insertOne/) or [review_boolean.insert_many(...)](https://docs.mongodb.com/manual/reference/method/db.collection.insertMany/). These functions take in a document or a list of documents and inserts them into the collection. \n",
    "\n",
    "*Updates*: In order to update a document, you may use the functions [review_boolean.update_one(...)](https://docs.mongodb.com/manual/reference/method/db.collection.updateOne/) or [review_boolean.update_many(...)](https://docs.mongodb.com/manual/reference/method/db.collection.updateMany/). These functions take in two parameters. The first specifies which documents should be modified. If the first parameter is `{}`, this indicates that all documents should be updated. However, you can put a more specific filter here if you would like. The second parameter specifies what you would like to update your field to (the [$set](https://docs.mongodb.com/manual/reference/operator/update/set/) operator may come in handy here). Recall that in our SQL model, updates are performed as `UPDATE ... SET ... WHERE ...`. In our case, the first ellipsis corresponds to `review_boolean`, the second ellipsis corresponds to the second parameter of `update_*`, and the third ellipsis corresponds to the first parameter of `update_*`.\n",
    "\n",
    "*Creation*: We handle creation of the collection for you. But in Pymongo, creation of a collection is as simple as writing `variable_name = db[collection_name]` where db is the the Pymongo database object variable you have already created.\n",
    "\n",
    "Some additional reminders and hints:\n",
    "- The empty collection `review_boolean` has already been created for you and is stored in the variable of the same name.\n",
    "- A text index has been created for you. You can use a similar search approach as the last question.\n",
    "- We want to start by inserting the documents from the `review` collection into the `review_boolean` collection.\n",
    "- Don't forget that in order to pass the hidden tests, the `to_avoid` field must exist for every document in `review_boolean`! The [$exists](https://www.mongodb.com/docs/manual/reference/operator/query/exists/) operator may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_boolean = mydb[\"review_boolean\"]\n",
    "review_boolean.drop()\n",
    "\n",
    "# We create a text index here\n",
    "if 'text_text' not in review_boolean.index_information():\n",
    "    review_boolean.create_index([('text', TEXT)])\n",
    "\n",
    "review_boolean.insert_many(list(review.find()))\n",
    "\n",
    "# Update the to_avoid field to true for documents that match the search query\n",
    "review_boolean.update_many(\n",
    "    {\"$text\": {\"$search\": \"disgusting horrid horrible gross bad hate\"}},\n",
    "    {\"$set\": {\"to_avoid\": \"true\"}}\n",
    ")\n",
    "\n",
    "review_boolean.update_many(\n",
    "    {\"to_avoid\": {\"$exists\": \"false\"}},\n",
    "    {\"$set\": {\"to_avoid\": \"false\"}}\n",
    ")\n",
    "\n",
    "rv_boolean = review_boolean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "review_boolean_1e = mydb[\"review_boolean\"]\n",
    "pickle.dump(list(review_boolean_1e.find({}, {'_id': 0})), open(\"results/result_1e.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1e</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1e results: All test cases passed!"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1f\n",
    "\n",
    "Now, you had a change of heart: you decide that it's unfair to label restaurants as `to_avoid` without at least giving them a chance! Remove the `to_avoid` field from the `review_boolean` collection. Calculate the `difference` between the data size of `review_boolean` with the `to_avoid` field and without it. The code for making this calculation is provided but it is up to you to actually remove the field.\n",
    "\n",
    "*Deletions*: Deletions in Mongo make use of the `review_boolean.update_one(...)` or `review_boolean.update_many(...)` functionality discussed in Question 1e. However, this time, instead of using the `$set` operator which allows for the creation of new fields, we will use the [$unset](https://docs.mongodb.com/manual/reference/operator/update/unset/) operator which deletes them! Very tidy!\n",
    "\n",
    "**Before running the next cell, make sure to re-run your cell for 1e so you don't get a difference of 0!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_avoid = mydb.command(\"collstats\", \"review_boolean\")['size']\n",
    "\n",
    "# YOUR ANSWER BEGINS HERE\n",
    "# END\n",
    "\n",
    "without_avoid = mydb.command(\"collstats\", \"review_boolean\")['size']\n",
    "difference = with_avoid - without_avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "pickle.dump(difference, open(\"results/result_1f.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q1f</pre> results:</strong></p><p><strong><pre style='display: inline;'>q1f - 1</pre> result:</strong></p><pre>    Trying:\n",
       "        difference = pickle.load(open(\"results/result_1f.p\", \"rb\"))\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        0 < difference <= 300000\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 2, in q1f 0\n",
       "    Failed example:\n",
       "        0 < difference <= 300000\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre>"
      ],
      "text/plain": [
       "q1f results:\n",
       "    q1f - 1 result:\n",
       "        Trying:\n",
       "            difference = pickle.load(open(\"results/result_1f.p\", \"rb\"))\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            0 < difference <= 300000\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q1f 0\n",
       "        Failed example:\n",
       "            0 < difference <= 300000\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: JSON and Relational Models\n",
    "\n",
    "### Question 2a\n",
    "\n",
    "Now we have a good idea of how to do retrieval, aggregation, and updates in Mongo. But we haven't talked about why we\n",
    "would want to use Mongo to store JSON! In order to explore this, let's take another look at the `business`\n",
    "collection. We will look at the first two entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('636dacbe71336d3423ea2668'),\n",
       "  'business_id': '6iYb2HFDywm3zjuRg0shjw',\n",
       "  'name': 'Oskar Blues Taproom',\n",
       "  'address': '921 Pearl St',\n",
       "  'city': 'Boulder',\n",
       "  'state': 'CO',\n",
       "  'postal_code': '80302',\n",
       "  'latitude': 40.0175444,\n",
       "  'longitude': -105.2833481,\n",
       "  'stars': 4.0,\n",
       "  'review_count': 86,\n",
       "  'is_open': 1,\n",
       "  'attributes': {'RestaurantsTableService': 'True',\n",
       "   'WiFi': \"u'free'\",\n",
       "   'BikeParking': 'True',\n",
       "   'BusinessParking': \"{'garage': False, 'street': True, 'validated': False, 'lot': False, 'valet': False}\",\n",
       "   'BusinessAcceptsCreditCards': 'True',\n",
       "   'RestaurantsReservations': 'False',\n",
       "   'WheelchairAccessible': 'True',\n",
       "   'Caters': 'True',\n",
       "   'OutdoorSeating': 'True',\n",
       "   'RestaurantsGoodForGroups': 'True',\n",
       "   'HappyHour': 'True',\n",
       "   'BusinessAcceptsBitcoin': 'False',\n",
       "   'RestaurantsPriceRange2': '2',\n",
       "   'Ambience': \"{'touristy': False, 'hipster': False, 'romantic': False, 'divey': False, 'intimate': False, 'trendy': False, 'upscale': False, 'classy': False, 'casual': True}\",\n",
       "   'HasTV': 'True',\n",
       "   'Alcohol': \"'beer_and_wine'\",\n",
       "   'GoodForMeal': \"{'dessert': False, 'latenight': False, 'lunch': False, 'dinner': False, 'brunch': False, 'breakfast': False}\",\n",
       "   'DogsAllowed': 'False',\n",
       "   'RestaurantsTakeOut': 'True',\n",
       "   'NoiseLevel': \"u'average'\",\n",
       "   'RestaurantsAttire': \"'casual'\",\n",
       "   'RestaurantsDelivery': 'None'},\n",
       "  'categories': 'Gastropubs, Food, Beer Gardens, Restaurants, Bars, American (Traditional), Beer Bar, Nightlife, Breweries',\n",
       "  'hours': {'Monday': '11:0-23:0',\n",
       "   'Tuesday': '11:0-23:0',\n",
       "   'Wednesday': '11:0-23:0',\n",
       "   'Thursday': '11:0-23:0',\n",
       "   'Friday': '11:0-23:0',\n",
       "   'Saturday': '11:0-23:0',\n",
       "   'Sunday': '11:0-23:0'}},\n",
       " {'_id': ObjectId('636dacbe71336d3423ea2669'),\n",
       "  'business_id': 'tCbdrRPZA0oiIYSmHG3J0w',\n",
       "  'name': 'Flying Elephants at PDX',\n",
       "  'address': '7000 NE Airport Way',\n",
       "  'city': 'Portland',\n",
       "  'state': 'OR',\n",
       "  'postal_code': '97218',\n",
       "  'latitude': 45.5889058992,\n",
       "  'longitude': -122.5933307507,\n",
       "  'stars': 4.0,\n",
       "  'review_count': 126,\n",
       "  'is_open': 1,\n",
       "  'attributes': {'RestaurantsTakeOut': 'True',\n",
       "   'RestaurantsAttire': \"u'casual'\",\n",
       "   'GoodForKids': 'True',\n",
       "   'BikeParking': 'False',\n",
       "   'OutdoorSeating': 'False',\n",
       "   'Ambience': \"{'romantic': False, 'intimate': False, 'touristy': False, 'hipster': False, 'divey': False, 'classy': False, 'trendy': False, 'upscale': False, 'casual': True}\",\n",
       "   'Caters': 'True',\n",
       "   'RestaurantsReservations': 'False',\n",
       "   'RestaurantsDelivery': 'False',\n",
       "   'HasTV': 'False',\n",
       "   'RestaurantsGoodForGroups': 'False',\n",
       "   'BusinessAcceptsCreditCards': 'True',\n",
       "   'NoiseLevel': \"u'average'\",\n",
       "   'ByAppointmentOnly': 'False',\n",
       "   'RestaurantsPriceRange2': '2',\n",
       "   'WiFi': \"u'free'\",\n",
       "   'BusinessParking': \"{'garage': True, 'street': False, 'validated': False, 'lot': False, 'valet': False}\",\n",
       "   'Alcohol': \"u'beer_and_wine'\",\n",
       "   'GoodForMeal': \"{'dessert': False, 'latenight': False, 'lunch': True, 'dinner': False, 'brunch': False, 'breakfast': True}\"},\n",
       "  'categories': 'Salad, Soup, Sandwiches, Delis, Restaurants, Cafes, Vegetarian',\n",
       "  'hours': {'Monday': '5:0-18:0',\n",
       "   'Tuesday': '5:0-17:0',\n",
       "   'Wednesday': '5:0-18:0',\n",
       "   'Thursday': '5:0-18:0',\n",
       "   'Friday': '5:0-18:0',\n",
       "   'Saturday': '5:0-18:0',\n",
       "   'Sunday': '5:0-18:0'}}]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(business.find({}).limit(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "What are **two** pros of storing this data in MongoDB with JSON over a relational database management system such as Postgres?\n",
    "Please reference specific examples from the `business` collection to back up your claims. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "manual: true\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### Question 2b\n",
    "\n",
    "It seems like MongoDB is getting all the love when it comes to JSON support! However, modern iterations of relational databases\n",
    "such as Postgres 9.3+ also have [excellent JSON functionality](https://www.postgresql.org/docs/9.3/functions-json.html) as we will soon explore in this task. First, let's set up a\n",
    "bit of scaffolding. The following cell will import the `yelp_academic_dataset_review.json` data into a table called `reviews` in Postgres yelp database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP DATABASE\n",
      "CREATE DATABASE\n",
      "NOTICE:  table \"reviews\" does not exist, skipping\n",
      "DROP TABLE\n",
      "CREATE TABLE\n",
      "COPY 7500\n",
      " * postgresql://jovyan@127.0.0.1:5432/postgres\n",
      "8 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>Name</th>\n",
       "        <th>Owner</th>\n",
       "        <th>Encoding</th>\n",
       "        <th>Collate</th>\n",
       "        <th>Ctype</th>\n",
       "        <th>Access privileges</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>baseball</td>\n",
       "        <td>jovyan</td>\n",
       "        <td>UTF8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>imdb</td>\n",
       "        <td>jovyan</td>\n",
       "        <td>UTF8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>jovyan</td>\n",
       "        <td>jovyan</td>\n",
       "        <td>UTF8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>postgres</td>\n",
       "        <td>jovyan</td>\n",
       "        <td>UTF8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>template0</td>\n",
       "        <td>jovyan</td>\n",
       "        <td>UTF8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>=c/jovyan<br>jovyan=CTc/jovyan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>template1</td>\n",
       "        <td>jovyan</td>\n",
       "        <td>UTF8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>=c/jovyan<br>jovyan=CTc/jovyan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ucb_buildings</td>\n",
       "        <td>jovyan</td>\n",
       "        <td>UTF8</td>\n",
       "        <td>en_US.UTF-8</td>\n",
       "        <td>en_US.UTF-8</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>yelp</td>\n",
       "        <td>jovyan</td>\n",
       "        <td>UTF8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>en_US.utf8</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('baseball', 'jovyan', 'UTF8', 'en_US.utf8', 'en_US.utf8', None),\n",
       " ('imdb', 'jovyan', 'UTF8', 'en_US.utf8', 'en_US.utf8', None),\n",
       " ('jovyan', 'jovyan', 'UTF8', 'en_US.utf8', 'en_US.utf8', None),\n",
       " ('postgres', 'jovyan', 'UTF8', 'en_US.utf8', 'en_US.utf8', None),\n",
       " ('template0',\n",
       "  'jovyan',\n",
       "  'UTF8',\n",
       "  'en_US.utf8',\n",
       "  'en_US.utf8',\n",
       "  '=c/jovyan\\njovyan=CTc/jovyan'),\n",
       " ('template1',\n",
       "  'jovyan',\n",
       "  'UTF8',\n",
       "  'en_US.utf8',\n",
       "  'en_US.utf8',\n",
       "  '=c/jovyan\\njovyan=CTc/jovyan'),\n",
       " ('ucb_buildings', 'jovyan', 'UTF8', 'en_US.UTF-8', 'en_US.UTF-8', None),\n",
       " ('yelp', 'jovyan', 'UTF8', 'en_US.utf8', 'en_US.utf8', None)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext sql\n",
    "%sql postgresql://jovyan@127.0.0.1:5432/postgres\n",
    "\n",
    "!psql -h localhost -c 'DROP DATABASE IF EXISTS yelp'\n",
    "!psql -h localhost -c 'CREATE DATABASE yelp'\n",
    "!psql -h localhost -d yelp -c 'DROP TABLE IF EXISTS reviews'\n",
    "!psql -h localhost -d yelp -c 'CREATE TABLE reviews(data TEXT);'\n",
    "!cat data/yelp_academic_dataset_review.json | psql -h localhost -d yelp -c \"COPY reviews (data) FROM STDIN;\"\n",
    "%sql \\l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the following cell to connect to the Postgres yelp database. There should be no errors after running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql postgresql://jovyan@127.0.0.1:5432/yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to observe how this new `reviews` table looks. Note that the `data` column is stored as TEXT and not as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/postgres\n",
      " * postgresql://jovyan@127.0.0.1:5432/yelp\n",
      "2 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>{&quot;review_id&quot;:&quot;lWC-xP3rd6obsecCYsGZRg&quot;,&quot;user_id&quot;:&quot;ak0TdVmGKo4pwqdJSTLwWw&quot;,&quot;business_id&quot;:&quot;buF9druCkbuXLX526sGELQ&quot;,&quot;stars&quot;:4.0,&quot;useful&quot;:3,&quot;funny&quot;:1,&quot;cool&quot;:1,&quot;text&quot;:&quot;Apparently Prides Osteria had a rough summer as evidenced by the almost empty dining room at 6:30 on a Friday night. However new blood in the kitchen seems to have revitalized the food from other customers recent visits. Waitstaff was warm but unobtrusive. By 8 pm or so when we left the bar was full and the dining room was much more lively than it had been. Perhaps Beverly residents prefer a later seating. <br><br>After reading the mixed reviews of late I was a little tentative over our choice but luckily there was nothing to worry about in the food department. We started with the fried dough, burrata and prosciutto which were all lovely. Then although they don&#x27;t offer half portions of pasta we each ordered the entree size and split them. We chose the tagliatelle bolognese and a four cheese filled pasta in a creamy sauce with bacon, asparagus and grana frita. Both were very good. We split a secondi which was the special Berkshire pork secreto, which was described as a pork skirt steak with garlic potato purée and romanesco broccoli (incorrectly described as a romanesco sauce). Some tables received bread before the meal but for some reason we did not. <br><br>Management also seems capable for when the tenants in the apartment above began playing basketball she intervened and also comped the tables a dessert. We ordered the apple dumpling with gelato and it was also quite tasty. Portions are not huge which I particularly like because I prefer to order courses. If you are someone who orders just a meal you may leave hungry depending on you appetite. Dining room was mostly younger crowd while the bar was definitely the over 40 set. Would recommend that the naysayers return to see the improvement although I personally don&#x27;t know the former glory to be able to compare. Easy access to downtown Salem without the crowds on this month of October.&quot;,&quot;date&quot;:&quot;2014-10-11 03:34:02&quot;}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>{&quot;review_id&quot;:&quot;8bFej1QE5LXp4O05qjGqXA&quot;,&quot;user_id&quot;:&quot;YoVfDbnISlW0f7abNQACIg&quot;,&quot;business_id&quot;:&quot;RA4V8pr014UyUbDvI-LW2A&quot;,&quot;stars&quot;:4.0,&quot;useful&quot;:1,&quot;funny&quot;:0,&quot;cool&quot;:0,&quot;text&quot;:&quot;This store is pretty good. Not as great as Walmart (or my preferred, Milford Target), but closer and in a easier area to get to.  <br>The store itself is pretty clean and organized, the staff are friendly (most of the time), and BEST of all is the Self Checkout this store has! <br>Great clearance sections throughout, and great prices on everything in the store, in general (they pricematch too!). <br>Christian, Debbie, Jen and Hanna are all very friendly, helpful, sensitive to all customer needs. Definitely one of the better Target locations in the area, and they do a GREAT job assisting customers for being such a busy store. Located directly in the Framingham Mall on Cochituate Rd / Route 30. 4 stars.&quot;,&quot;date&quot;:&quot;2015-07-03 20:38:25&quot;}</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('{\"review_id\":\"lWC-xP3rd6obsecCYsGZRg\",\"user_id\":\"ak0TdVmGKo4pwqdJSTLwWw\",\"business_id\":\"buF9druCkbuXLX526sGELQ\",\"stars\":4.0,\"useful\":3,\"funny\":1,\"coo ... (1757 characters truncated) ... now the former glory to be able to compare. Easy access to downtown Salem without the crowds on this month of October.\",\"date\":\"2014-10-11 03:34:02\"}',),\n",
       " ('{\"review_id\":\"8bFej1QE5LXp4O05qjGqXA\",\"user_id\":\"YoVfDbnISlW0f7abNQACIg\",\"business_id\":\"RA4V8pr014UyUbDvI-LW2A\",\"stars\":4.0,\"useful\":1,\"funny\":0,\"coo ... (599 characters truncated) ... g customers for being such a busy store. Located directly in the Framingham Mall on Cochituate Rd / Route 30. 4 stars.\",\"date\":\"2015-07-03 20:38:25\"}',)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT * FROM reviews LIMIT 2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how the reviews table consists of one column named `data`. This column contains all the JSON documents in the \n",
    "reviews collection *in text format*. Use [Postgres' JSON functions](https://www.postgresql.org/docs/9.3/functions-json.html) to write a query that converts the JSON fields into their own `TEXT` columns (hint: one of the operators in Table 9-40 may be useful). To be more concrete, your query should contain 8 columns in this particular order: `review_id`, `user_id`, `business_id`, `stars`, `useful`, `funny`, `cool`, and `text`. Each row should correspond to one JSON document. Some skeleton code (that does the mundane work of converting data to JSON properly) is provided to you - you will only need to fill in the SELECT clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/postgres\n",
      " * postgresql://jovyan@127.0.0.1:5432/yelp\n",
      "10 rows affected.\n",
      "Returning data to local variable result_2b\n"
     ]
    }
   ],
   "source": [
    "%%sql result_2b <<\n",
    "SELECT b.values ->> 'review_id' AS review_id,\n",
    "       b.values ->> 'user_id' AS user_id,\n",
    "       b.values ->> 'business_id' AS business_id,\n",
    "       b.values ->> 'stars' AS stars,\n",
    "       b.values ->> 'useful' AS useful,\n",
    "       b.values ->> 'funny' AS funny,\n",
    "       b.values ->> 'cool' AS cool,\n",
    "       b.values ->> 'text' AS text\n",
    "FROM (SELECT CAST(regexp_replace(data, E'[\\\\n\\\\r]+', '','g') AS JSON) AS values FROM reviews) b\n",
    "ORDER BY review_id\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_2b.DataFrame().to_csv('results/result_2b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2b</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2b results: All test cases passed!"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2c\n",
    "\n",
    "One important aspect of data engineering that we have not referred to yet are joins. We saw, through the use of indices, selection/projection pushdown, and various physical implementations (as well as orderings), joins could be done quite efficiently in relational SQL based databases. How do joins fare in Mongo where the data stored is inherently semistructured? Let's investigate! For this question, we have provided you access to the tables `business_complete` and `review_complete` which contain the business and review collections in relational form as described in 2b (the columns of the relations\n",
    "are fields in the JSON document). Each relation has its respective id (`business_id` or `review_id`) column as its primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTICE:  table \"business_complete\" does not exist, skipping\n",
      "DROP TABLE\n",
      "CREATE TABLE\n",
      "NOTICE:  table \"review_complete\" does not exist, skipping\n",
      "DROP TABLE\n",
      "CREATE TABLE\n",
      "COPY 35\n",
      "COPY 7500\n"
     ]
    }
   ],
   "source": [
    "!psql -h localhost -d yelp -c 'DROP TABLE IF EXISTS business_complete'\n",
    "!psql -h localhost -d yelp -c 'CREATE TABLE business_complete(business_id TEXT PRIMARY KEY, name TEXT, address TEXT, city TEXT, state TEXT, postal_code TEXT, latitude TEXT,longitude TEXT, stars TEXT, review_count TEXT, is_open TEXT, attributes TEXT, categories TEXT, hours TEXT);'\n",
    "!psql -h localhost -d yelp -c 'DROP TABLE IF EXISTS review_complete'\n",
    "!psql -h localhost -d yelp -c 'CREATE TABLE review_complete(review_id TEXT PRIMARY KEY, user_id TEXT, business_id TEXT, stars TEXT, useful TEXT, funny TEXT, cool TEXT,text TEXT);'\n",
    "!cat data/business.csv | psql -h localhost -d yelp -c \"COPY business_complete (business_id,name,address,city,state,postal_code,latitude,longitude,stars,review_count,is_open,attributes,categories,hours) FROM STDIN CSV HEADER;\"\n",
    "!cat data/review.csv | psql -h localhost -d yelp -c \"COPY review_complete (review_id, user_id, business_id, stars, useful, funny, cool, text) FROM STDIN CSV HEADER;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how `review_complete` looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://jovyan@127.0.0.1:5432/postgres\n",
      " * postgresql://jovyan@127.0.0.1:5432/yelp\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>review_id</th>\n",
       "        <th>user_id</th>\n",
       "        <th>business_id</th>\n",
       "        <th>stars</th>\n",
       "        <th>useful</th>\n",
       "        <th>funny</th>\n",
       "        <th>cool</th>\n",
       "        <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>lWC-xP3rd6obsecCYsGZRg</td>\n",
       "        <td>ak0TdVmGKo4pwqdJSTLwWw</td>\n",
       "        <td>buF9druCkbuXLX526sGELQ</td>\n",
       "        <td>4.0</td>\n",
       "        <td>3</td>\n",
       "        <td>1</td>\n",
       "        <td>1</td>\n",
       "        <td>Apparently Prides Osteria had a rough summer as evidenced by the almost empty dining room at 6:30 on a Friday night. However new blood in the kitchen seems to have revitalized the food from other customers recent visits. Waitstaff was warm but unobtrusive. By 8 pm or so when we left the bar was full and the dining room was much more lively than it had been. Perhaps Beverly residents prefer a later seating. After reading the mixed reviews of late I was a little tentative over our choice but luckily there was nothing to worry about in the food department. We started with the fried dough, burrata and prosciutto which were all lovely. Then although they don&#x27;t offer half portions of pasta we each ordered the entree size and split them. We chose the tagliatelle bolognese and a four cheese filled pasta in a creamy sauce with bacon, asparagus and grana frita. Both were very good. We split a secondi which was the special Berkshire pork secreto, which was described as a pork skirt steak with garlic potato purée and romanesco broccoli (incorrectly described as a romanesco sauce). Some tables received bread before the meal but for some reason we did not. Management also seems capable for when the tenants in the apartment above began playing basketball she intervened and also comped the tables a dessert. We ordered the apple dumpling with gelato and it was also quite tasty. Portions are not huge which I particularly like because I prefer to order courses. If you are someone who orders just a meal you may leave hungry depending on you appetite. Dining room was mostly younger crowd while the bar was definitely the over 40 set. Would recommend that the naysayers return to see the improvement although I personally don&#x27;t know the former glory to be able to compare. Easy access to downtown Salem without the crowds on this month of October.</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('lWC-xP3rd6obsecCYsGZRg', 'ak0TdVmGKo4pwqdJSTLwWw', 'buF9druCkbuXLX526sGELQ', '4.0', '3', '1', '1', \"Apparently Prides Osteria had a rough summer as evidenced by the almost empty dining room at 6:30 on a Friday night. However new blood in the kitchen ... (1554 characters truncated) ... t although I personally don't know the former glory to be able to compare. Easy access to downtown Salem without the crowds on this month of October.\")]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT * FROM review_complete LIMIT 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this current moment in time, Mongo only supports left joins (via the lookup aggregation stage). This is what we will compare against SQL.\n",
    "\n",
    "Let's start by writing a SQL query that displays all the reviews along with their associated business information. You should perform a **left join** between the `review_complete` table and the `business_complete` table on the `business_id` column, and you may project all columns. Keep a mental note of the **execution time** that you see in the query plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         QUERY PLAN                                                          \r\n",
      "-----------------------------------------------------------------------------------------------------------------------------\r\n",
      " Hash Left Join  (cost=13.82..778.08 rows=15792 width=704) (actual time=0.092..4.649 rows=7500 loops=1)\r\n",
      "   Hash Cond: (review_complete.business_id = business_complete.business_id)\r\n",
      "   ->  Seq Scan on review_complete  (cost=0.00..721.92 rows=15792 width=256) (actual time=0.007..2.388 rows=7500 loops=1)\r\n",
      "   ->  Hash  (cost=11.70..11.70 rows=170 width=448) (actual time=0.063..0.065 rows=35 loops=1)\r\n",
      "         Buckets: 1024  Batches: 1  Memory Usage: 32kB\r\n",
      "         ->  Seq Scan on business_complete  (cost=0.00..11.70 rows=170 width=448) (actual time=0.011..0.022 rows=35 loops=1)\r\n",
      " Planning Time: 0.776 ms\r\n",
      " Execution Time: 4.987 ms\r\n",
      "(8 rows)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "result_2c_str = \"SELECT * FROM review_complete LEFT JOIN business_complete ON review_complete.business_id = business_complete.business_id\"\n",
    "!psql -h localhost -d yelp -c \"explain analyze $result_2c_str\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's perform the equivalent left join in Mongo between `review` and `business`. **The output array field should be named as `business_info`**. Feel free to refer to the `$lookup` documentation: https://docs.mongodb.com/manual/reference/operator/aggregation/lookup/.\n",
    "\n",
    "**Note:** You will provide a single-stage pipeline to `review.aggregate(...)` as your solution. Save your pipeline to `q2c_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first create an index on business_id in the business collection\n",
    "business.create_index('business_id', unique=True)\n",
    "\n",
    "q2c_pipeline = [{\n",
    "'$lookup': {\n",
    "'from': 'business',\n",
    "'foreignField': 'business_id',\n",
    "'localField': 'business_id',\n",
    "'as': 'business_info'\n",
    "}\n",
    "}]\n",
    "\n",
    "result_2c = list(review.aggregate(q2c_pipeline))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_2c = list(review.aggregate(q2c_pipeline))[:5]\n",
    "pickle.dump(result_2c, open(\"results/result_2c.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2c</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2c results: All test cases passed!"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to examine the query plan for the Mongo query that you just wrote. Again, make a mental note of the execution time that you see (you can find the value corresponding to the key `executionTimeMillis`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explainVersion': '1',\n",
       " 'stages': [{'$cursor': {'queryPlanner': {'namespace': 'yelp.review',\n",
       "     'indexFilterSet': False,\n",
       "     'parsedQuery': {},\n",
       "     'queryHash': '8B3D4AB8',\n",
       "     'planCacheKey': 'D542626C',\n",
       "     'maxIndexedOrSolutionsReached': False,\n",
       "     'maxIndexedAndSolutionsReached': False,\n",
       "     'maxScansToExplodeReached': False,\n",
       "     'winningPlan': {'stage': 'COLLSCAN', 'direction': 'forward'},\n",
       "     'rejectedPlans': []},\n",
       "    'executionStats': {'executionSuccess': True,\n",
       "     'nReturned': 7500,\n",
       "     'executionTimeMillis': 543,\n",
       "     'totalKeysExamined': 0,\n",
       "     'totalDocsExamined': 7500,\n",
       "     'executionStages': {'stage': 'COLLSCAN',\n",
       "      'nReturned': 7500,\n",
       "      'executionTimeMillisEstimate': 1,\n",
       "      'works': 7502,\n",
       "      'advanced': 7500,\n",
       "      'needTime': 1,\n",
       "      'needYield': 0,\n",
       "      'saveState': 10,\n",
       "      'restoreState': 10,\n",
       "      'isEOF': 1,\n",
       "      'direction': 'forward',\n",
       "      'docsExamined': 7500}}},\n",
       "   'nReturned': 7500,\n",
       "   'executionTimeMillisEstimate': 7},\n",
       "  {'$lookup': {'from': 'business',\n",
       "    'as': 'business_info',\n",
       "    'localField': 'business_id',\n",
       "    'foreignField': 'business_id'},\n",
       "   'totalDocsExamined': 7500,\n",
       "   'totalKeysExamined': 7500,\n",
       "   'collectionScans': 0,\n",
       "   'indexesUsed': ['business_id_1'],\n",
       "   'nReturned': 7500,\n",
       "   'executionTimeMillisEstimate': 544}],\n",
       " 'serverInfo': {'host': 'jupyter-arushi-5fsharma',\n",
       "  'port': 27017,\n",
       "  'version': '5.0.11',\n",
       "  'gitVersion': 'd08c3c41c105cde798ca934e3ac3426ac11b57c3'},\n",
       " 'serverParameters': {'internalQueryFacetBufferSizeBytes': 104857600,\n",
       "  'internalQueryFacetMaxOutputDocSizeBytes': 104857600,\n",
       "  'internalLookupStageIntermediateDocumentMaxSizeBytes': 104857600,\n",
       "  'internalDocumentSourceGroupMaxMemoryBytes': 104857600,\n",
       "  'internalQueryMaxBlockingSortMemoryUsageBytes': 104857600,\n",
       "  'internalQueryProhibitBlockingMergeOnMongoS': 0,\n",
       "  'internalQueryMaxAddToSetBytes': 104857600,\n",
       "  'internalDocumentSourceSetWindowFieldsMaxMemoryBytes': 104857600},\n",
       " 'command': {'aggregate': 'review',\n",
       "  'pipeline': [{'$lookup': {'from': 'business',\n",
       "     'foreignField': 'business_id',\n",
       "     'localField': 'business_id',\n",
       "     'as': 'business_info'}}],\n",
       "  'cursor': {},\n",
       "  '$db': 'yelp'},\n",
       " 'ok': 1.0}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydb.command('explain', {'aggregate': 'review', 'pipeline': q2c_pipeline, 'cursor': {}}, verbosity='executionStats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2d\n",
    "\n",
    "In the last question, you performed equivalent left joins in both Postgres and Mongo, and examined their query plans. Which join was faster? What gives that database system you chose an advantage over the other?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2d\n",
    "manual: true\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Question 3: Dataframes / Pandas\n",
    "\n",
    "### Question 3a\n",
    "\n",
    "So far, we've talked about NoSQL / document databases like Mongo and relational databases like Postgres. Now, we will explore data transformation with a different data model: dataframes. Dataframes are similar to relations with some differences as we will dive into here. To that end, we will use Pandas which is a Python package that allows you to work with dataframes. Pandas is widely adopted by data scientists for data loading, wrangling, cleaning, and analysis. To start, let us export our MongoDB collections into Pandas using a function called `json_normalize`. We need to truncate\n",
    "`business` before we can use it to meet the memory constraints set by Jupyter. The variable `business_trunc` will contain the reference the truncated business collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_trunc = mydb[\"business_trunc\"]\n",
    "count = 0\n",
    "if business_trunc.count_documents({}) != 1000:\n",
    "    for document in business.find({}):\n",
    "        count += 1\n",
    "        business_trunc.insert_one(document)\n",
    "        if count == 1000:\n",
    "            break\n",
    "\n",
    "business_cursor = business_trunc.find({})\n",
    "review_cursor = mydb[\"reviews\"].find({})\n",
    "user_cursor = mydb[\"users\"].find({})\n",
    "\n",
    "# Load the collections into Pandas. \n",
    "from pandas import json_normalize\n",
    "user_df = json_normalize(user_cursor)\n",
    "review_df = json_normalize(review_cursor)\n",
    "business_df = json_normalize(business_cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of Question 3, please use the 3 dataframes we just created: `user_df`, `review_df`, and `business_df`. Let's take a look at the first 5 rows of `business_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>...</th>\n",
       "      <th>attributes.GoodForDancing</th>\n",
       "      <th>attributes.BestNights</th>\n",
       "      <th>attributes.Music</th>\n",
       "      <th>attributes.BYOB</th>\n",
       "      <th>attributes.CoatCheck</th>\n",
       "      <th>attributes.Smoking</th>\n",
       "      <th>attributes.DriveThru</th>\n",
       "      <th>attributes.BYOBCorkage</th>\n",
       "      <th>attributes.Corkage</th>\n",
       "      <th>attributes.RestaurantsCounterService</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>636dacbe71336d3423ea2668</td>\n",
       "      <td>6iYb2HFDywm3zjuRg0shjw</td>\n",
       "      <td>Oskar Blues Taproom</td>\n",
       "      <td>921 Pearl St</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>CO</td>\n",
       "      <td>80302</td>\n",
       "      <td>40.017544</td>\n",
       "      <td>-105.283348</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>636dacbe71336d3423ea2669</td>\n",
       "      <td>tCbdrRPZA0oiIYSmHG3J0w</td>\n",
       "      <td>Flying Elephants at PDX</td>\n",
       "      <td>7000 NE Airport Way</td>\n",
       "      <td>Portland</td>\n",
       "      <td>OR</td>\n",
       "      <td>97218</td>\n",
       "      <td>45.588906</td>\n",
       "      <td>-122.593331</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>636dacbe71336d3423ea266a</td>\n",
       "      <td>bvN78flM8NLprQ1a1y5dRg</td>\n",
       "      <td>The Reclaimory</td>\n",
       "      <td>4720 Hawthorne Ave</td>\n",
       "      <td>Portland</td>\n",
       "      <td>OR</td>\n",
       "      <td>97214</td>\n",
       "      <td>45.511907</td>\n",
       "      <td>-122.613693</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>636dacbe71336d3423ea266b</td>\n",
       "      <td>oaepsyvc0J17qwi8cfrOWg</td>\n",
       "      <td>Great Clips</td>\n",
       "      <td>2566 Enterprise Rd</td>\n",
       "      <td>Orange City</td>\n",
       "      <td>FL</td>\n",
       "      <td>32763</td>\n",
       "      <td>28.914482</td>\n",
       "      <td>-81.295979</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636dacbe71336d3423ea266c</td>\n",
       "      <td>PE9uqAjdw0E4-8mjGl3wVA</td>\n",
       "      <td>Crossfit Terminus</td>\n",
       "      <td>1046 Memorial Dr SE</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30316</td>\n",
       "      <td>33.747027</td>\n",
       "      <td>-84.353424</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id             business_id                     name  \\\n",
       "0  636dacbe71336d3423ea2668  6iYb2HFDywm3zjuRg0shjw      Oskar Blues Taproom   \n",
       "1  636dacbe71336d3423ea2669  tCbdrRPZA0oiIYSmHG3J0w  Flying Elephants at PDX   \n",
       "2  636dacbe71336d3423ea266a  bvN78flM8NLprQ1a1y5dRg           The Reclaimory   \n",
       "3  636dacbe71336d3423ea266b  oaepsyvc0J17qwi8cfrOWg              Great Clips   \n",
       "4  636dacbe71336d3423ea266c  PE9uqAjdw0E4-8mjGl3wVA        Crossfit Terminus   \n",
       "\n",
       "               address         city state postal_code   latitude   longitude  \\\n",
       "0         921 Pearl St      Boulder    CO       80302  40.017544 -105.283348   \n",
       "1  7000 NE Airport Way     Portland    OR       97218  45.588906 -122.593331   \n",
       "2   4720 Hawthorne Ave     Portland    OR       97214  45.511907 -122.613693   \n",
       "3   2566 Enterprise Rd  Orange City    FL       32763  28.914482  -81.295979   \n",
       "4  1046 Memorial Dr SE      Atlanta    GA       30316  33.747027  -84.353424   \n",
       "\n",
       "   stars  ...  attributes.GoodForDancing  attributes.BestNights  \\\n",
       "0    4.0  ...                        NaN                    NaN   \n",
       "1    4.0  ...                        NaN                    NaN   \n",
       "2    4.5  ...                        NaN                    NaN   \n",
       "3    3.0  ...                        NaN                    NaN   \n",
       "4    4.0  ...                        NaN                    NaN   \n",
       "\n",
       "  attributes.Music attributes.BYOB attributes.CoatCheck attributes.Smoking  \\\n",
       "0              NaN             NaN                  NaN                NaN   \n",
       "1              NaN             NaN                  NaN                NaN   \n",
       "2              NaN             NaN                  NaN                NaN   \n",
       "3              NaN             NaN                  NaN                NaN   \n",
       "4              NaN             NaN                  NaN                NaN   \n",
       "\n",
       "  attributes.DriveThru attributes.BYOBCorkage attributes.Corkage  \\\n",
       "0                  NaN                    NaN                NaN   \n",
       "1                  NaN                    NaN                NaN   \n",
       "2                  NaN                    NaN                NaN   \n",
       "3                  NaN                    NaN                NaN   \n",
       "4                  NaN                    NaN                NaN   \n",
       "\n",
       "  attributes.RestaurantsCounterService  \n",
       "0                                  NaN  \n",
       "1                                  NaN  \n",
       "2                                  NaN  \n",
       "3                                  NaN  \n",
       "4                                  NaN  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "What do you notice about how the columns of `business_df` are constructed? Compare and contrast this dataframe representation with the document representation we saw with Mongo.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### Question 3b\n",
    "\n",
    "In the previous question, we talked about how Mongo and Postgres approach joins. Pandas is also capable of performing joins using the [merge()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) function! For this task, perform a inner join on `business_df` with itself on `stars`. The final dataframe should be saved to a variable called `result_3b` and should only contain 3 columns in this particular order: the name of the first restaurant, the name of the second restaurant, and the number of the stars. The column names can be arbitrary.\n",
    "\n",
    "**Hint:** Check out [this tutorial](https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html) on selecting a subset of the Dataframe. This will be helpful in the rest of Question 3 as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3b = pd.merge(business_df, business_df, on='stars', how='inner')[['name_x', 'name_y', 'stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_3b.columns = ['first', 'second', 'stars']\n",
    "result_3b.sort_values(['first', 'second', 'stars'])[:50].to_csv('results/result_3b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3b</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3b results: All test cases passed!"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3c\n",
    "\n",
    "Due to the nested representation of the data, there are a lot of missing fields with NaN values in the `business_df` dataframe as you may have noticed in 3a. Construct a dataframe `missing_value_df` with two columns: `column_name` and `percent_missing`. `percent_missing` should be the percentage of NaN values in the corresponding column in `business_df`.\n",
    "\n",
    "**Hint:** use Pandas' [isnull()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html) function followed by sum()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'column_name': business_df.columns, 'nan_count': business_df.isnull().sum()})\n",
    "missing_value_df = temp_df.assign(percent_missing = temp_df['nan_count'] / len(business_df))[['column_name', 'percent_missing']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "missing_value_df.to_csv('results/result_3c.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3c</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3c results: All test cases passed!"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3d\n",
    "\n",
    "Plot a histogram distribution of the percentage of NaN values across all columns (via Pandas [hist()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html) function). Don't worry about putting titles / making it look nice - we won't be grading the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGdCAYAAADnrPLBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjxElEQVR4nO3de3BU5eHG8WdNyBJoCAKGEAkQK4iAIoK2VSpEBQsRFaZWVCACdqCCBOKFpF7xQoJWikoFtQ5gKRcvQPGGRrmJ1gsJQdAOCAYSIDTjpRsCZYHs+/vDcX9dQyDZbPacF7+fmfPHec97dp95B80zZ8/Z9RhjjAAAACx1mtMBAAAAGoIyAwAArEaZAQAAVqPMAAAAq1FmAACA1SgzAADAapQZAABgNcoMAACwWqzTARpbIBDQvn37lJCQII/H43QcAABQB8YYHThwQCkpKTrttBNfeznly8y+ffuUmprqdAwAABCGsrIytW/f/oRzTvkyk5CQIOn7xWjRooXDaQAAQF1UVlYqNTU1+Hf8RE75MvPDR0stWrSgzAAAYJm63CLCDcAAAMBqlBkAAGA1ygwAALAaZQYAAFiNMgMAAKxGmQEAAFajzAAAAKtRZgAAgNUoMwAAwGqUGQAAYDVHy8z69es1ZMgQpaSkyOPxaMWKFTXm/Otf/9I111yjxMREJSQk6Je//KVKS0ujHxYAALiSo2Xm4MGD6tmzp2bPnn3c4zt37lTfvn3VtWtXrV27Vps3b9Z9992npk2bRjkpAABwK48xxjgdQvr+h6SWL1+u6667Ljg2fPhwNWnSRH/729/Cft3KykolJibK5/PxQ5MAAFiiPn+/XXvPTCAQ0BtvvKEuXbroqquuUlJSkn7xi18c96Oo/+X3+1VZWRmyAQCAU1es0wFqU1FRoaqqKuXn5+uRRx7RjBkztGrVKg0bNkxr1qxRv379jnteXl6epk2bFuW0AAA0XKecN5yOUG+78jOcjuDuKzOSdO2112rKlCm64IILlJOTo6uvvlpz586t9bzc3Fz5fL7gVlZWFq3IAADAAa69MtOmTRvFxsaqW7duIePnnnuuNmzYUOt5Xq9XXq+3seMBAACXcO2Vmbi4OF100UXatm1byPj27dvVsWNHh1IBAAC3cfTKTFVVlXbs2BHcLykpUXFxsVq1aqUOHTrorrvu0g033KDLLrtM6enpWrVqlV577TWtXbvWudAAAMBVHC0zGzduVHp6enA/OztbkpSZman58+dr6NChmjt3rvLy8jRp0iSdc845evXVV9W3b1+nIgMAAJdxtMz0799fJ/uamzFjxmjMmDFRSgQAAGzj2ntmAAAA6oIyAwAArEaZAQAAVqPMAAAAq1FmAACA1SgzAADAapQZAABgNcoMAACwGmUGAABYjTIDAACsRpkBAABWo8wAAACrUWYAAIDVKDMAAMBqlBkAAGA1ygwAALAaZQYAAFiNMgMAAKxGmQEAAFajzAAAAKtRZgAAgNUoMwAAwGqUGQAAYDXKDAAAsBplBgAAWI0yAwAArEaZAQAAVqPMAAAAq1FmAACA1SgzAADAapQZAABgNcoMAACwGmUGAABYzdEys379eg0ZMkQpKSnyeDxasWJFrXPHjRsnj8ejWbNmRS0fAABwP0fLzMGDB9WzZ0/Nnj37hPNWrFihjz/+WCkpKVFKBgAAbBHr5JsPGjRIgwYNOuGcvXv3auLEiXr77beVkZERpWQAAMAWjpaZkwkEAho5cqTuuusude/evU7n+P1++f3+4H5lZWVjxQMAAC7g6huAZ8yYodjYWE2aNKnO5+Tl5SkxMTG4paamNmJCAADgNNeWmcLCQj355JOaP3++PB5Pnc/Lzc2Vz+cLbmVlZY2YEgAAOM21Zeb9999XRUWFOnTooNjYWMXGxmr37t2644471KlTp1rP83q9atGiRcgGAABOXa69Z2bkyJG68sorQ8auuuoqjRw5UqNHj3YoFQAAcBtHy0xVVZV27NgR3C8pKVFxcbFatWqlDh06qHXr1iHzmzRpouTkZJ1zzjnRjgoAAFzK0TKzceNGpaenB/ezs7MlSZmZmZo/f75DqQAAgE0cLTP9+/eXMabO83ft2tV4YQAAgJVcewMwAABAXVBmAACA1SgzAADAapQZAABgNcoMAACwGmUGAABYjTIDAACsRpkBAABWo8wAAACrUWYAAIDVKDMAAMBqlBkAAGA1ygwAALAaZQYAAFiNMgMAAKwW63QA23XKecPpCPW2Kz/D6QgAAEQMV2YAAIDVKDMAAMBqlBkAAGA1ygwAALAaZQYAAFiNMgMAAKxGmQEAAFajzAAAAKtRZgAAgNUoMwAAwGqUGQAAYDXKDAAAsBplBgAAWI0yAwAArEaZAQAAVqPMAAAAq1FmAACA1RwtM+vXr9eQIUOUkpIij8ejFStWBI8dPXpUU6dO1XnnnafmzZsrJSVFo0aN0r59+5wLDAAAXMfRMnPw4EH17NlTs2fPrnHs0KFDKioq0n333aeioiItW7ZM27dv1zXXXONAUgAA4FaxTr75oEGDNGjQoOMeS0xMVEFBQcjY008/rYsvvlilpaXq0KFDNCICAACXc7TM1JfP55PH41HLli1rneP3++X3+4P7lZWVUUgGAACcYs0NwIcPH1ZOTo5uuukmtWjRotZ5eXl5SkxMDG6pqalRTAkAAKLNijJz9OhRDR8+XIFAQM8888wJ5+bm5srn8wW3srKyKKUEAABOcP3HTEePHtXvfvc7lZSUaPXq1Se8KiNJXq9XXq83SukAAIDTXF1mfigyX375pdasWaPWrVs7HQkAALiMo2WmqqpKO3bsCO6XlJSouLhYrVq1UkpKin7729+qqKhIr7/+uqqrq7V//35JUqtWrRQXF+dUbAAA4CKOlpmNGzcqPT09uJ+dnS1JyszM1IMPPqiVK1dKki644IKQ89asWaP+/ftHKyYAAHAxR8tM//79ZYyp9fiJjgEAAEiWPM0EAABQG8oMAACwGmUGAABYjTIDAACsRpkBAABWo8wAAACrUWYAAIDVKDMAAMBqlBkAAGA1ygwAALAaZQYAAFiNMgMAAKxGmQEAAFajzAAAAKtRZgAAgNUoMwAAwGqUGQAAYDXKDAAAsBplBgAAWI0yAwAArEaZAQAAVqPMAAAAq1FmAACA1SgzAADAapQZAABgNcoMAACwGmUGAABYjTIDAACsRpkBAABWo8wAAACrUWYAAIDVKDMAAMBqlBkAAGA1R8vM+vXrNWTIEKWkpMjj8WjFihUhx40xevDBB5WSkqL4+Hj1799fn3/+uTNhAQCAKzlaZg4ePKiePXtq9uzZxz3+2GOPaebMmZo9e7Y+/fRTJScna8CAATpw4ECUkwIAALeKdfLNBw0apEGDBh33mDFGs2bN0j333KNhw4ZJkhYsWKC2bdtq0aJFGjduXDSjAgAAl3LtPTMlJSXav3+/Bg4cGBzzer3q16+fPvzww1rP8/v9qqysDNkAAMCpy7VlZv/+/ZKktm3bhoy3bds2eOx48vLylJiYGNxSU1MbNScAAHCWa8vMDzweT8i+MabG2P/Kzc2Vz+cLbmVlZY0dEQAAOMjRe2ZOJDk5WdL3V2jatWsXHK+oqKhxteZ/eb1eeb3eRs8HAADcIawrMyUlJZHOUUNaWpqSk5NVUFAQHDty5IjWrVunSy65pNHfHwAA2CGsMnP22WcrPT1dCxcu1OHDh8N+86qqKhUXF6u4uFjS9yWpuLhYpaWl8ng8mjx5sqZPn67ly5dr69atuuWWW9SsWTPddNNNYb8nAAA4tYRVZjZv3qxevXrpjjvuUHJyssaNG6dPPvmk3q+zceNG9erVS7169ZIkZWdnq1evXrr//vslSXfffbcmT56s2267TX369NHevXv1zjvvKCEhIZzYAADgFOQxxphwTz527Jhee+01zZ8/X2+99ZY6d+6ssWPHauTIkTrjjDMimTNslZWVSkxMlM/nU4sWLSL++p1y3oj4aza2XfkZTkcAABwHf1P+X33+fjfoaabY2FgNHTpUL730kmbMmKGdO3fqzjvvVPv27TVq1CiVl5c35OUBAABOqkFlZuPGjbrtttvUrl07zZw5U3feead27typ1atXa+/evbr22msjlRMAAOC4wno0e+bMmZo3b562bdumwYMH68UXX9TgwYN12mnfd6O0tDQ9++yz6tq1a0TDAgAA/FhYZWbOnDkaM2aMRo8eHfw+mB/r0KGDXnjhhQaFAwAAOJmwysyXX3550jlxcXHKzMwM5+UBAADqLKx7ZubNm6eXX365xvjLL7+sBQsWNDgUAABAXYVVZvLz89WmTZsa40lJSZo+fXqDQwEAANRVWGVm9+7dSktLqzHesWNHlZaWNjgUAABAXYVVZpKSkvTZZ5/VGN+8ebNat27d4FAAAAB1FVaZGT58uCZNmqQ1a9aourpa1dXVWr16tbKysjR8+PBIZwQAAKhVWE8zPfLII9q9e7euuOIKxcZ+/xKBQECjRo3inhkAABBVYZWZuLg4LV26VA8//LA2b96s+Ph4nXfeeerYsWOk8wEAAJxQWGXmB126dFGXLl0ilQUAAKDewioz1dXVmj9/vt577z1VVFQoEAiEHF+9enVEwgEAAJxMWGUmKytL8+fPV0ZGhnr06CGPxxPpXAAAAHUSVplZsmSJXnrpJQ0ePDjSeQAALtQp5w2nI9TbrvwMpyMgSsJ6NDsuLk5nn312pLMAAADUW1hl5o477tCTTz4pY0yk8wAAANRLWB8zbdiwQWvWrNFbb72l7t27q0mTJiHHly1bFpFwAAAAJxNWmWnZsqWGDh0a6SwAAAD1FlaZmTdvXqRzAAAAhCWse2Yk6dixY3r33Xf17LPP6sCBA5Kkffv2qaqqKmLhAAAATiasKzO7d+/Wb37zG5WWlsrv92vAgAFKSEjQY489psOHD2vu3LmRzgkAAHBcYV2ZycrKUp8+ffTdd98pPj4+OD506FC99957EQsHAABwMmE/zfTBBx8oLi4uZLxjx47au3dvRIIBAADURVhXZgKBgKqrq2uM79mzRwkJCQ0OBQAAUFdhlZkBAwZo1qxZwX2Px6Oqqio98MAD/MQBAACIqrA+Zvrzn/+s9PR0devWTYcPH9ZNN92kL7/8Um3atNHixYsjnREAAKBWYZWZlJQUFRcXa/HixSoqKlIgENDYsWN18803h9wQDAAA0NjCKjOSFB8frzFjxmjMmDGRzAMAAFAvYZWZF1988YTHR40aFVYYAACA+gqrzGRlZYXsHz16VIcOHVJcXJyaNWtGmQEAAFET1tNM3333XchWVVWlbdu2qW/fvtwADAAAoirs32b6sc6dOys/P7/GVZuGOHbsmO69916lpaUpPj5eZ511lh566CEFAoGIvQcAALBb2DcAH09MTIz27dsXsdebMWOG5s6dqwULFqh79+7auHGjRo8ercTExIiWJgAAYK+wyszKlStD9o0xKi8v1+zZs3XppZdGJJgk/fOf/9S1116rjIwMSVKnTp20ePFibdy4MWLvAQAA7BZWmbnuuutC9j0ej8444wxdfvnleuKJJyKRS5LUt29fzZ07V9u3b1eXLl20efNmbdiwIeTbh3/M7/fL7/cH9ysrKyOWBwAAuE9YZSZa96xMnTpVPp9PXbt2VUxMjKqrq/Xoo4/qxhtvrPWcvLw8TZs2LSr5AACA8yJ2A3BjWLp0qRYuXKhFixapqKhICxYs0J/+9CctWLCg1nNyc3Pl8/mCW1lZWRQTAwCAaAvrykx2dnad586cOTOct5Ak3XXXXcrJydHw4cMlSeedd552796tvLw8ZWZmHvccr9crr9cb9nsCAAC7hFVmNm3apKKiIh07dkznnHOOJGn79u2KiYnRhRdeGJzn8XgaFO7QoUM67bTQi0cxMTE8mg0AAILCKjNDhgxRQkKCFixYoNNPP13S91+kN3r0aP3617/WHXfcEZFwQ4YM0aOPPqoOHTqoe/fu2rRpk2bOnMnvQQEAgKCwyswTTzyhd955J1hkJOn000/XI488ooEDB0aszDz99NO67777dNttt6miokIpKSkaN26c7r///oi8PgAAsF9YZaayslL//ve/1b1795DxiooKHThwICLBJCkhIUGzZs064aPYAADgpy2sp5mGDh2q0aNH65VXXtGePXu0Z88evfLKKxo7dqyGDRsW6YwAAAC1CuvKzNy5c3XnnXdqxIgROnr06PcvFBursWPH6vHHH49oQAAAgBMJq8w0a9ZMzzzzjB5//HHt3LlTxhidffbZat68eaTzAQAAnFCDvjSvvLxc5eXl6tKli5o3by5jTKRyAQAA1ElYZeabb77RFVdcoS5dumjw4MEqLy+XJN16660Re5IJAACgLsIqM1OmTFGTJk1UWlqqZs2aBcdvuOEGrVq1KmLhAAAATiase2beeecdvf3222rfvn3IeOfOnbV79+6IBAMAAKiLsK7MHDx4MOSKzA++/vprfhcJAABEVVhl5rLLLtOLL74Y3Pd4PAoEAnr88ceVnp4esXAAAAAnE9bHTI8//rj69++vjRs36siRI7r77rv1+eef69tvv9UHH3wQ6YwAAAC1CuvKTLdu3fTZZ5/p4osv1oABA3Tw4EENGzZMmzZt0s9//vNIZwQAAKhVva/MHD16VAMHDtSzzz6radOmNUYmAACAOqv3lZkmTZpo69at8ng8jZEHAACgXsL6mGnUqFF64YUXIp0FAACg3sK6AfjIkSP661//qoKCAvXp06fGbzLNnDkzIuEAAABOpl5l5quvvlKnTp20detWXXjhhZKk7du3h8zh4ycAABBN9SoznTt3Vnl5udasWSPp+58veOqpp9S2bdtGCQcAAHAy9bpn5se/iv3WW2/p4MGDEQ0EAABQH2HdAPyDH5cbAACAaKtXmfF4PDXuieEeGQAA4KR63TNjjNEtt9wS/DHJw4cPa/z48TWeZlq2bFnkEgIAAJxAvcpMZmZmyP6IESMiGgYAAKC+6lVm5s2b11g5AAAAwtKgG4ABAACcRpkBAABWo8wAAACrUWYAAIDVKDMAAMBqlBkAAGA1ygwAALAaZQYAAFiNMgMAAKxGmQEAAFZzfZnZu3evRowYodatW6tZs2a64IILVFhY6HQsAADgEvX6baZo++6773TppZcqPT1db731lpKSkrRz5061bNnS6WgAAMAlXF1mZsyYodTU1JAfuOzUqZNzgQAAgOu4+mOmlStXqk+fPrr++uuVlJSkXr166fnnnz/hOX6/X5WVlSEbAAA4dbm6zHz11VeaM2eOOnfurLffflvjx4/XpEmT9OKLL9Z6Tl5enhITE4NbampqFBMDAIBoc3WZCQQCuvDCCzV9+nT16tVL48aN0+9//3vNmTOn1nNyc3Pl8/mCW1lZWRQTAwCAaHN1mWnXrp26desWMnbuueeqtLS01nO8Xq9atGgRsgEAgFOXq8vMpZdeqm3btoWMbd++XR07dnQoEQAAcBtXl5kpU6boo48+0vTp07Vjxw4tWrRIzz33nCZMmOB0NAAA4BKuLjMXXXSRli9frsWLF6tHjx56+OGHNWvWLN18881ORwMAAC7h6u+ZkaSrr75aV199tdMxAACAS7n6ygwAAMDJUGYAAIDVKDMAAMBqlBkAAGA1ygwAALAaZQYAAFiNMgMAAKxGmQEAAFajzAAAAKtRZgAAgNUoMwAAwGqUGQAAYDXKDAAAsBplBgAAWI0yAwAArBbrdAAA+KnplPOG0xGAUwpXZgAAgNUoMwAAwGqUGQAAYDXKDAAAsBplBgAAWI0yAwAArEaZAQAAVqPMAAAAq1FmAACA1SgzAADAapQZAABgNcoMAACwGmUGAABYjTIDAACsRpkBAABWo8wAAACrUWYAAIDVrCozeXl58ng8mjx5stNRAACAS1hTZj799FM999xzOv/8852OAgAAXMSKMlNVVaWbb75Zzz//vE4//XSn4wAAABexosxMmDBBGRkZuvLKK0861+/3q7KyMmQDAACnrlinA5zMkiVLVFRUpE8//bRO8/Py8jRt2rRGTmW3TjlvOB2h3nblZzgdAYBlbPx/HcLj6iszZWVlysrK0sKFC9W0adM6nZObmyufzxfcysrKGjklAABwkquvzBQWFqqiokK9e/cOjlVXV2v9+vWaPXu2/H6/YmJiQs7xer3yer3RjgoAABzi6jJzxRVXaMuWLSFjo0ePVteuXTV16tQaRQYAAPz0uLrMJCQkqEePHiFjzZs3V+vWrWuMAwCAnyZX3zMDAABwMq6+MnM8a9eudToCAABwEa7MAAAAq1FmAACA1SgzAADAapQZAABgNcoMAACwGmUGAABYjTIDAACsRpkBAABWo8wAAACrUWYAAIDVKDMAAMBqlBkAAGA1ygwAALAaZQYAAFiNMgMAAKwW63QAoC465bzhdIR625Wf4XQEAPhJ4MoMAACwGmUGAABYjTIDAACsRpkBAABWo8wAAACrUWYAAIDVKDMAAMBqlBkAAGA1ygwAALAaZQYAAFiNMgMAAKxGmQEAAFajzAAAAKtRZgAAgNUoMwAAwGqUGQAAYDXKDAAAsJqry0xeXp4uuugiJSQkKCkpSdddd522bdvmdCwAAOAiri4z69at04QJE/TRRx+poKBAx44d08CBA3Xw4EGnowEAAJeIdTrAiaxatSpkf968eUpKSlJhYaEuu+wyh1IBAAA3cXWZ+TGfzydJatWqVa1z/H6//H5/cL+ysrLRcwEAAOdYU2aMMcrOzlbfvn3Vo0ePWufl5eVp2rRpUUwGnDo65bzhdIR625Wf4XQEAA5z9T0z/2vixIn67LPPtHjx4hPOy83Nlc/nC25lZWVRSggAAJxgxZWZ22+/XStXrtT69evVvn37E871er3yer1RSgYAAJzm6jJjjNHtt9+u5cuXa+3atUpLS3M6EgAAcBlXl5kJEyZo0aJF+sc//qGEhATt379fkpSYmKj4+HiH0wEAADdw9T0zc+bMkc/nU//+/dWuXbvgtnTpUqejAQAAl3D1lRljjNMRAACAy7n6ygwAAMDJUGYAAIDVKDMAAMBqlBkAAGA1ygwAALAaZQYAAFiNMgMAAKxGmQEAAFajzAAAAKtRZgAAgNUoMwAAwGqUGQAAYDXKDAAAsBplBgAAWI0yAwAArBbrdADgVNUp5w2nI/wksM4AuDIDAACsRpkBAABWo8wAAACrUWYAAIDVKDMAAMBqlBkAAGA1ygwAALAaZQYAAFiNMgMAAKxGmQEAAFajzAAAAKtRZgAAgNUoMwAAwGqUGQAAYDXKDAAAsBplBgAAWI0yAwAArGZFmXnmmWeUlpampk2bqnfv3nr//fedjgQAAFzC9WVm6dKlmjx5su655x5t2rRJv/71rzVo0CCVlpY6HQ0AALiA68vMzJkzNXbsWN16660699xzNWvWLKWmpmrOnDlORwMAAC4Q63SAEzly5IgKCwuVk5MTMj5w4EB9+OGHxz3H7/fL7/cH930+nySpsrKyUTIG/Ica5XUBALBBY/19/eF1jTEnnevqMvP111+rurpabdu2DRlv27at9u/ff9xz8vLyNG3atBrjqampjZIRAICfssRZjfv6Bw4cUGJi4gnnuLrM/MDj8YTsG2NqjP0gNzdX2dnZwf1AIKBvv/1WrVu3rvWccFVWVio1NVVlZWVq0aJFRF8b/491jg7WOTpY5+hgnaOjMdfZGKMDBw4oJSXlpHNdXWbatGmjmJiYGldhKioqalyt+YHX65XX6w0Za9myZWNFlCS1aNGC/1iigHWODtY5Oljn6GCdo6Ox1vlkV2R+4OobgOPi4tS7d28VFBSEjBcUFOiSSy5xKBUAAHATV1+ZkaTs7GyNHDlSffr00a9+9Ss999xzKi0t1fjx452OBgAAXMD1ZeaGG27QN998o4ceekjl5eXq0aOH3nzzTXXs2NHpaPJ6vXrggQdqfKyFyGKdo4N1jg7WOTpY5+hwyzp7TF2eeQIAAHApV98zAwAAcDKUGQAAYDXKDAAAsBplBgAAWI0yE6ZnnnlGaWlpatq0qXr37q3333/f6UhWy8vL00UXXaSEhAQlJSXpuuuu07Zt20LmGGP04IMPKiUlRfHx8erfv78+//xzhxKfGvLy8uTxeDR58uTgGOscGXv37tWIESPUunVrNWvWTBdccIEKCwuDx1nnhjt27JjuvfdepaWlKT4+XmeddZYeeughBQKB4BzWOTzr16/XkCFDlJKSIo/HoxUrVoQcr8u6+v1+3X777WrTpo2aN2+ua665Rnv27GmcwAb1tmTJEtOkSRPz/PPPmy+++MJkZWWZ5s2bm927dzsdzVpXXXWVmTdvntm6daspLi42GRkZpkOHDqaqqio4Jz8/3yQkJJhXX33VbNmyxdxwww2mXbt2prKy0sHk9vrkk09Mp06dzPnnn2+ysrKC46xzw3377bemY8eO5pZbbjEff/yxKSkpMe+++67ZsWNHcA7r3HCPPPKIad26tXn99ddNSUmJefnll83PfvYzM2vWrOAc1jk8b775prnnnnvMq6++aiSZ5cuXhxyvy7qOHz/enHnmmaagoMAUFRWZ9PR007NnT3Ps2LGI56XMhOHiiy8248ePDxnr2rWrycnJcSjRqaeiosJIMuvWrTPGGBMIBExycrLJz88Pzjl8+LBJTEw0c+fOdSqmtQ4cOGA6d+5sCgoKTL9+/YJlhnWOjKlTp5q+ffvWepx1joyMjAwzZsyYkLFhw4aZESNGGGNY50j5cZmpy7r+5z//MU2aNDFLliwJztm7d6857bTTzKpVqyKekY+Z6unIkSMqLCzUwIEDQ8YHDhyoDz/80KFUpx6fzydJatWqlSSppKRE+/fvD1l3r9erfv36se5hmDBhgjIyMnTllVeGjLPOkbFy5Ur16dNH119/vZKSktSrVy89//zzweOsc2T07dtX7733nrZv3y5J2rx5szZs2KDBgwdLYp0bS13WtbCwUEePHg2Zk5KSoh49ejTK2rv+G4Dd5uuvv1Z1dXWNH7ps27ZtjR/ERHiMMcrOzlbfvn3Vo0cPSQqu7fHWfffu3VHPaLMlS5aoqKhIn376aY1jrHNkfPXVV5ozZ46ys7P1xz/+UZ988okmTZokr9erUaNGsc4RMnXqVPl8PnXt2lUxMTGqrq7Wo48+qhtvvFES/54bS13Wdf/+/YqLi9Ppp59eY05j/K2kzITJ4/GE7BtjaowhPBMnTtRnn32mDRs21DjGujdMWVmZsrKy9M4776hp06a1zmOdGyYQCKhPnz6aPn26JKlXr176/PPPNWfOHI0aNSo4j3VumKVLl2rhwoVatGiRunfvruLiYk2ePFkpKSnKzMwMzmOdG0c469pYa8/HTPXUpk0bxcTE1GiWFRUVNVoq6u/222/XypUrtWbNGrVv3z44npycLEmsewMVFhaqoqJCvXv3VmxsrGJjY7Vu3To99dRTio2NDa4l69ww7dq1U7du3ULGzj33XJWWlkri33Ok3HXXXcrJydHw4cN13nnnaeTIkZoyZYry8vIksc6NpS7rmpycrCNHjui7776rdU4kUWbqKS4uTr1791ZBQUHIeEFBgS655BKHUtnPGKOJEydq2bJlWr16tdLS0kKOp6WlKTk5OWTdjxw5onXr1rHu9XDFFVdoy5YtKi4uDm59+vTRzTffrOLiYp111lmscwRceumlNb5aYPv27cEfyOXfc2QcOnRIp50W+mcsJiYm+Gg269w46rKuvXv3VpMmTULmlJeXa+vWrY2z9hG/pfgn4IdHs1944QXzxRdfmMmTJ5vmzZubXbt2OR3NWn/4wx9MYmKiWbt2rSkvLw9uhw4dCs7Jz883iYmJZtmyZWbLli3mxhtv5BHLCPjfp5mMYZ0j4ZNPPjGxsbHm0UcfNV9++aX5+9//bpo1a2YWLlwYnMM6N1xmZqY588wzg49mL1u2zLRp08bcfffdwTmsc3gOHDhgNm3aZDZt2mQkmZkzZ5pNmzYFv4KkLus6fvx40759e/Puu++aoqIic/nll/Nottv85S9/MR07djRxcXHmwgsvDD5CjPBIOu42b9684JxAIGAeeOABk5ycbLxer7nsssvMli1bnAt9ivhxmWGdI+O1114zPXr0MF6v13Tt2tU899xzIcdZ54arrKw0WVlZpkOHDqZp06bmrLPOMvfcc4/x+/3BOaxzeNasWXPc/ydnZmYaY+q2rv/973/NxIkTTatWrUx8fLy5+uqrTWlpaaPk9RhjTOSv9wAAAEQH98wAAACrUWYAAIDVKDMAAMBqlBkAAGA1ygwAALAaZQYAAFiNMgMAAKxGmQEAAFajzAAAAKtRZgAAgNUoMwAAwGqUGQAAYLX/A7woMisIx1H7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "percent_missing = business_df.isnull().sum() * 100 / len(business_df)\n",
    "percent_missing.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Examine the histogram that you just plotted. How many columns are 90%+ NaN? Input your answer into `result_q3d` as an integer (e.g. if your answer is 6, then `result_q3d = 6`)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3d\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_q3d = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3d</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3d results: All test cases passed!"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3e\n",
    "\n",
    "Let us now alter `business_df` to exclude the columns with more than 80%+ null values (keep columns with 80% null values or less). This likely means the corresponding attributes are not an important factor for most businesses so we can get rid of them in our `business_df`. Create a new dataframe called `important_attribute_business_df` which only contains these columns.\n",
    "\n",
    "**Hint:** check out [this section](https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html#how-do-i-select-specific-rows-and-columns-from-a-dataframe) from the tutorial linked in Q3b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = business_df.isnull().sum() / len(business_df)\n",
    "cols_to_drop = percent_missing[percent_missing > 0.8].index\n",
    "important_attribute_business_df = business_df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "important_attribute_business_df.to_csv('results/result_3e.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3e</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3e results: All test cases passed!"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3f\n",
    "\n",
    "At this point, you have had experience with manipulating data on Mongo, Postgres, and Pandas. In this question, we will provide 3 scenarios and using the lessons you've learned so far, please specify which of the three (Mongo, Postgres, or Pandas) would work best for this specific use case.\n",
    "\n",
    "1. You are doing a data journalism piece on college sports. You collect a list of colleges and for each collegiate sport program within that college, you find the budget assigned for that program. You have a choice between the following:\n",
    "\n",
    "    A) Representing this data in JSON (e.g. \n",
    "    ```\n",
    "    {\n",
    "        \"UC Berkeley\": {\n",
    "            \"football\": \"10000000\", \n",
    "            \"wrestling\": \"344582\", \n",
    "            ...}\n",
    "    }\n",
    "    ```\n",
    "    ) and importing into Mongo.\n",
    "    \n",
    "    B) Representing this data as a schema in Postgres where the columns are the names of the sports.\n",
    "    \n",
    "    C) Representing this data as a dataframe in Pandas where the columns are the names of the sports.\n",
    "\n",
    "You would like to find the aggregate of budgets across different sports (average, sum, median, mode). What would be the best option for storing this data?\n",
    "\n",
    "**NOTE**: Your answer should look like `q3fi_str = ['A']` or `q3fi_str = ['B']` or `q3fi_str = ['C']`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3fi\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3fi_str = ['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3fi</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3fi results: All test cases passed!"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3fi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "2. You would now like to investigate what effect does budget have on student-athlete scholarships. After doing some research, you find a dataset that contains a list of every single athlete at every single college and their sport and scholarship levels (this is a massive 10GB+ dataset with millions of rows). You find another dataset that contains a list of colleges, their sports programs, and the program budget. This is another massive dataset with hundreds of thousands of rows. You would like to perform an inner join between the two datasets on school and program so you can view each student-athlete's scholarship with their sport's budget. You have a choice between the following:\n",
    "\n",
    "    A) Representing each dataset in JSON (e.g. \n",
    "    ```\n",
    "    {\"athletes\": [\n",
    "        {\"Chase Garbers\": {\n",
    "            \"school\": \"UC Berkeley\", \n",
    "            \"scholarship\": \"full\", \n",
    "            \"sport\": \"football\", \n",
    "            ...\n",
    "            }\n",
    "        }, \n",
    "        ...\n",
    "    ]}\n",
    "    ```\n",
    "    and \n",
    "    ```\n",
    "    {\"schools\": [\n",
    "        {\"UC Berkeley\": {\n",
    "            \"football\": {\n",
    "                \"budget\": \"10000000\"\n",
    "             }, \n",
    "             ...\n",
    "             }\n",
    "        }, \n",
    "        ...\n",
    "     ]}\n",
    "     ```\n",
    "    ), importing into Mongo, and doing a join there.\n",
    "    \n",
    "    B) Representing this data as 2 schemas in Postgres where the columns for the first schema are \n",
    "    [`student_name`, `school`, `sport`, `scholarship`] and for the second [`school`, `sport`, `budget`].\n",
    "    \n",
    "    C) Representing this data as 2 dataframes in Pandas with the same columns as Postgres.\n",
    "\n",
    "What would be the best option for storing this data?\n",
    "\n",
    "**NOTE**: Your answer should look like `q3fii_str = ['A']` or `q3fii_str = ['B']` or `q3fii_str = ['C']` or `q3fii_str = ['D']`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3fii\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3fii_str = ['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3fii</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3fii results: All test cases passed!"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3fii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "3. Finally, you are ready to start writing your article! You decide to focus on just the data from UC Berkeley. You have access to a dataset of just UC Berkeley athletes along with their sports and scholarship levels. The scholarship level data was improperly cleaned: some scholarships are recorded as strings \"full\", \"half\", or \"none\" and some are recorded as integer percentages 0-100. You would like to provide this data to your readers in a format that is susceptible to easy visualizations: e.g. graphs that show how many athletes have a full vs. half vs. no scholarship, which sports have the highest percentages of athletes with full scholarships etc. What is the best way to store this data for this purpose?\n",
    "\n",
    "    A) Represent the dataset in JSON e.g.\n",
    "    ```\n",
    "    {\"athletes\": [\n",
    "        {\n",
    "           \"Chase Garbers\": {\n",
    "             \"scholarship\": \"full\", \n",
    "             \"sport\": \"football\"\n",
    "           }\n",
    "        },\n",
    "        {\n",
    "            \"Danielle Vosk\": {\n",
    "              \"scholarship\": 25,\n",
    "              \"sport\": \"basketball\"\n",
    "            }\n",
    "        },\n",
    "        ...\n",
    "        ]\n",
    "    }\n",
    "    ```\n",
    "    B) Represent this data as a schema in Postgres where the columns are [`student_name`, `sport`, `scholarship`]\n",
    "    \n",
    "    C) Represent this data as a dataframe in Pandas with the same columns as Postgres.\n",
    "    \n",
    "**NOTE**: Your answer should look like `q3fiii_str = ['A']` or `q3fiii_str = ['B']` or `q3fiii_str = ['C']` or `q3fiii_str = ['D']`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3fiii\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3fiii_str = ['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3fiii</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3fiii results: All test cases passed!"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3fiii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Messy JSON\n",
    "\n",
    "Many of the queries you've seen or written thus far were relatively reliable: aggregating and collecting over fields\n",
    "that you know exist for sure. But the nature of Mongo documents is that they are inherently flexible and semi-structured. Not every document will share every single field! In this question, we will explore how Mongo handles these use cases using the `business` collection.\n",
    "\n",
    "### Question 4a\n",
    "\n",
    "Imagine you are in charge of managing your family reunion. You would like to book a private room at a restaurant.\n",
    "However, you would also like to optimize for chaos. You notice that there is an attribute called `RestaurantsGoodForGroups`. You would like to write a query that returns all restaurants that **do not** have the `RestaurantsGoodForGroups` attribute so that the trajectory of the reunion is determined by fate (hint: search up the `$exists` keyword). Your output for the autograder will be the integer number of restaurants that do not have the `RestaurantsGoodForGroups` attribute stored in `q4a_str`. \n",
    "\n",
    "**Note:** You would like this list to consist solely of restaurants. This means that the business must have `Restaurants` in the `categories` field. You may perform a similar text search as question 1d. **This holds true for the rest of the Question 4 as well!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following text index may be useful!\n",
    "if 'categories_text' not in business.index_information():\n",
    "    business.create_index([('categories', TEXT)])\n",
    "\n",
    "q4a_str = len((list(business.find({'$text' : {'$search' : 'Restaurants'},\n",
    "    'attributes.RestaurantsGoodForGroups' : {'$exists' : False}}))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many restaurants do not have the `RestaurantsGoodForGroups` attribute? You may either enter input this is a function with respect to your query or hardcode in either the String or the numeric version of the answer you computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "pickle.dump(q4a_str, open(\"results/result_4a.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4a</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4a results: All test cases passed!"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4b\n",
    "\n",
    "Your relatives inform you that they would like to be at the restaurant when it opens to beat the crowds. Furthermore, after sending\n",
    "a when2meet, most of your relatives would prefer for the meal to be on a Friday and the start time of the meal to be \n",
    "between 5-6:59PM (17:00-18:59). Find the number of restaurants that open on Fridays between 17:00-18:59 (you only have to consider the opening time!) and store this in a variable labeled `q4b_str`. As a reminder, in order for a business to be a restaurant, it must have `Restaurant` in its categories. Be aware that `hours` can either be an array or `None`!\n",
    "\n",
    "**Hint**: Set up an aggregation pipeline using the `$set` and `$match` stage operators. You may also want to use the `$split` operator to parse out the Friday hours. Note that using dot notation for array indexing in aggregation pipelines may not work as expected, so we recommend using `$arrayElemAt` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4b_str = len(list(business.aggregate([\n",
    "    {'$match':{'$text' : {'$search' : 'Restaurants'}}},\n",
    "    {'$set' : {'entry' : {'$split' : ['$hours.Friday', ':']}}}, \n",
    "    {'$set' : {'entry2' : {'$arrayElemAt' : ['$entry', 0]}}},\n",
    "    {'$match' : {'$or': [{'entry2' : '17'}, {'entry2' : '18'}]}}\n",
    "])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "pickle.dump(q4b_str, open(\"results/result_4b.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4b</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4b results: All test cases passed!"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4c\n",
    "\n",
    "Some members of your family are vegetarian so you would like to only eat at restaurants with the Vegetarian category. \n",
    "However, the `categories` are stored as a single string! You would like to make it easy to access Vegetarian as a separate field. Write a query that does the following: for every category in `categories`, add a new document that contains the `ObjectId` for the previous document (labeled `_id`), the name of the business (labeled `name`), and the category (labeled `category`).\n",
    "\n",
    "For example, a document \n",
    "```\n",
    "{\n",
    "    \"_id\": ObjectId('606ffb0123cf2e5079dbd91f'), \n",
    "    \"name\": \"Wendy's\", \n",
    "     ..., \n",
    "     categories\" : \"Salad, Vegetarian\"\n",
    "} \n",
    "```\n",
    "would become \n",
    "```\n",
    "{\n",
    "    \"_id\": ObjectId('606ffb0123cf2e5079dbd91f'), \n",
    "    \"name\": \"Wendy's\",\n",
    "    “category”: \"Salad\"\n",
    "}\n",
    "```\n",
    "and \n",
    "```\n",
    "{\n",
    "    \"_id\": ObjectId('606ffb0123cf2e5079dbd91f'), \n",
    "    \"name\": \"Wendy's\",\n",
    "    “category”: \"Vegetarian\"\n",
    "}\n",
    "```\n",
    "\n",
    "Finally, to ensure your output is consistent with the autograder, sort in ascending order by `name` and break ties on `category`. Save your pipeline to a variable called `q4c_pipeline`.\n",
    "\n",
    "**Hint:** the `$unwind` operator may be helpful here. Watch out to make sure you don't have any unnecessary space in the `category` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q4c_pipeline = [\n",
    "    {'$match' : {'$text' : {'$search' : 'Restaurants'}}}, \n",
    "    {'$set' : {'category' : {'$split' : ['$categories',', ']}}},\n",
    "    {'$unwind' : '$category'}, \n",
    "    {'$project' : {'_id' : 1, 'name' : 1, 'category' : 1}}, \n",
    "    {'$sort' : {'name' : 1, 'category' : 1}}\n",
    "]\n",
    "\n",
    "result_4c = list(business.aggregate(q4c_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "result_4c = list(business.aggregate(q4c_pipeline))[10000:10050]\n",
    "pickle.dump(result_4c, open(\"results/result_4c.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4c</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4c results: All test cases passed!"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4d\n",
    "This change in representation has made it super easy to view all the vegetarian restaurants and count them without the use of an index since we can now simply filter by whether or not 'Vegetarian' is a field in our document! We have provided some code here to count how many vegetarian restaurants are in our dataset. Simply provide the integer count to get a point for this question :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4d_pipeline = q4c_pipeline[:]\n",
    "q4d_pipeline.append({\"$match\": {\"category\": 'Vegetarian'}})\n",
    "result_4d = list(business.aggregate(q4d_pipeline))\n",
    "\n",
    "veg_count = len(result_4d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell\n",
    "pickle.dump(veg_count, open(\"results/result_4d.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4d</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4d results: All test cases passed!"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You have finished Project 4.\n",
    "\n",
    "Run the following cell to zip and download the results of your queries. You will also need to run the export cell at the end of the notebook.\n",
    "\n",
    "**For submission on Gradescope, you will need to submit BOTH the proj4.zip file genreated by the export cell and the results.zip file generated by the following cell.**\n",
    "\n",
    "**Common submission issues:** You MUST submit the generated zip files (not folders) to the autograder. However, Safari is known to automatically unzip files upon downloading. You can fix this by going into Safari preferences, and deselect the box with the text \"Open safe files after downloading\" under the \"General\" tab. If you experience issues with downloading via clicking on the link, you can also navigate to the project 4 directory within JupyterHub (remove `proj4.ipynb` from the url), and manually download the generated zip files. Please post on Ed if you encounter any other submission issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: results/ (stored 0%)\n",
      "  adding: results/result_1a.p (deflated 13%)\n",
      "  adding: results/result_1b.p (deflated 10%)\n",
      "  adding: results/result_1c.p (deflated 75%)\n",
      "  adding: results/result_1d.p (deflated 20%)\n",
      "  adding: results/result_2b.csv (deflated 46%)\n",
      "  adding: results/result_2c.p (deflated 58%)\n",
      "  adding: results/result_3b.csv (deflated 69%)\n",
      "  adding: results/result_3c.csv (deflated 59%)\n",
      "  adding: results/result_3e.csv (deflated 74%)\n",
      "  adding: results/result_1e.p (deflated 59%)\n",
      "  adding: results/result_1f.p (stored 0%)\n",
      "  adding: results/result_4a.p (deflated 20%)\n",
      "  adding: results/result_4b.p (deflated 20%)\n",
      "  adding: results/result_4c.p (deflated 85%)\n",
      "  adding: results/result_4d.p (deflated 20%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Click here to download: <a href='./results.zip' target='_blank'>./results.zip</a><br>"
      ],
      "text/plain": [
       "/home/jovyan/fa22/proj/proj4/results.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, FileLink\n",
    "\n",
    "!zip -r results.zip results\n",
    "results_file = FileLink('./results.zip', result_html_prefix=\"Click here to download: \")\n",
    "display(results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
